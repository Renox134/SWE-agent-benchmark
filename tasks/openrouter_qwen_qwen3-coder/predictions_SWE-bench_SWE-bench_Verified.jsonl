{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "matplotlib__matplotlib-26291", "model_patch": "diff --git a/lib/mpl_toolkits/axes_grid1/inset_locator.py b/lib/mpl_toolkits/axes_grid1/inset_locator.py\nindex 9d35051074..70132b0daa 100644\n--- a/lib/mpl_toolkits/axes_grid1/inset_locator.py\n+++ b/lib/mpl_toolkits/axes_grid1/inset_locator.py\n@@ -70,6 +70,9 @@ class AnchoredLocatorBase(AnchoredOffsetbox):\n \n     def __call__(self, ax, renderer):\n         self.axes = ax\n+        # Handle case where renderer is None and self.figure is None\n+        if renderer is None and self.figure is None and ax.figure is not None:\n+            renderer = ax.figure._get_renderer()\n         bbox = self.get_window_extent(renderer)\n         px, py = self.get_offset(bbox.width, bbox.height, 0, 0, renderer)\n         bbox_canvas = Bbox.from_bounds(px, py, bbox.width, bbox.height)\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "matplotlib__matplotlib-26291", "model_patch": "diff --git a/lib/mpl_toolkits/axes_grid1/inset_locator.py b/lib/mpl_toolkits/axes_grid1/inset_locator.py\nindex 9d35051074..70132b0daa 100644\n--- a/lib/mpl_toolkits/axes_grid1/inset_locator.py\n+++ b/lib/mpl_toolkits/axes_grid1/inset_locator.py\n@@ -70,6 +70,9 @@ class AnchoredLocatorBase(AnchoredOffsetbox):\n \n     def __call__(self, ax, renderer):\n         self.axes = ax\n+        # Handle case where renderer is None and self.figure is None\n+        if renderer is None and self.figure is None and ax.figure is not None:\n+            renderer = ax.figure._get_renderer()\n         bbox = self.get_window_extent(renderer)\n         px, py = self.get_offset(bbox.width, bbox.height, 0, 0, renderer)\n         bbox_canvas = Bbox.from_bounds(px, py, bbox.width, bbox.height)\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "matplotlib__matplotlib-26342", "model_patch": "diff --git a/lib/matplotlib/contour.py b/lib/matplotlib/contour.py\nindex 3f84250b64..2e3b35969b 100644\n--- a/lib/matplotlib/contour.py\n+++ b/lib/matplotlib/contour.py\n@@ -1475,6 +1475,30 @@ class ContourSet(ContourLabeler, mcoll.Collection):\n             ):\n                 super().draw(renderer)\n \n+    def set_paths(self, paths):\n+        \"\"\"\n+        Set the paths for the contour set.\n+        \n+        Parameters\n+        ----------\n+        paths : list of Path\n+            List of Path objects to set as the paths for this contour set.\n+        \"\"\"\n+        # Validate that paths is iterable\n+        try:\n+            iter(paths)\n+        except TypeError:\n+            raise TypeError(\"paths must be iterable\")\n+        \n+        # Convert to list and validate each element is a Path\n+        path_list = list(paths)\n+        for path in path_list:\n+            if not isinstance(path, Path):\n+                raise TypeError(\"All elements in paths must be Path objects\")\n+        \n+        self._paths = path_list\n+        self.stale = True\n+\n \n @_docstring.dedent_interpd\n class QuadContourSet(ContourSet):\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "matplotlib__matplotlib-26466", "model_patch": "diff --git a/lib/matplotlib/text.py b/lib/matplotlib/text.py\nindex d4922fc517..a0858e6205 100644\n--- a/lib/matplotlib/text.py\n+++ b/lib/matplotlib/text.py\n@@ -1456,7 +1456,7 @@ class _AnnotationBase:\n                  xycoords='data',\n                  annotation_clip=None):\n \n-        self.xy = xy\n+        self.xy = np.array(xy) if isinstance(xy, (list, tuple, np.ndarray)) else xy\n         self.xycoords = xycoords\n         self.set_annotation_clip(annotation_clip)\n \n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "mwaskom__seaborn-3187", "model_patch": "diff --git a/seaborn/_core/plot.py b/seaborn/_core/plot.py\nindex 8915616b..5ec74e6e 100644\n--- a/seaborn/_core/plot.py\n+++ b/seaborn/_core/plot.py\n@@ -1561,7 +1561,13 @@ class Plotter:\n         for var in legend_vars:\n             var_legend = scales[var]._legend\n             if var_legend is not None:\n-                values, labels = var_legend\n+                # Unpack the legend information\n+                if len(var_legend) == 3:  # New format with offset\n+                    values, labels, offset = var_legend\n+                else:  # Old format without offset\n+                    values, labels = var_legend\n+                    offset = None\n+                \n                 for (_, part_id), part_vars, _ in schema:\n                     if data.ids[var] == part_id:\n                         # Allow multiple plot semantics to represent same data variable\n@@ -1569,6 +1575,9 @@ class Plotter:\n                         break\n                 else:\n                     title = self._resolve_label(p, var, data.names[var])\n+                    # Add offset information to the title if available\n+                    if offset:\n+                        title = f\"{title} (+{offset})\"\n                     entry = (title, data.ids[var]), [var], (values, labels)\n                     schema.append(entry)\n \ndiff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\nindex 55874bf2..6c716d3b 100644\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -379,7 +379,13 @@ class ContinuousBase(Scale):\n             locs = axis.major.locator()\n             locs = locs[(vmin <= locs) & (locs <= vmax)]\n             labels = axis.major.formatter.format_ticks(locs)\n-            new._legend = list(locs), list(labels)\n+            \n+            # Handle offset notation for ScalarFormatter\n+            offset = None\n+            if isinstance(axis.major.formatter, mpl.ticker.ScalarFormatter):\n+                offset = axis.major.formatter.get_offset()\n+            \n+            new._legend = list(locs), list(labels), offset\n \n         return new\n \n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pallets__flask-5014", "model_patch": "diff --git a/src/flask/blueprints.py b/src/flask/blueprints.py\nindex eb50585d..d69945e8 100644\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -190,6 +190,9 @@ class Blueprint(Scaffold):\n             root_path=root_path,\n         )\n \n+        if not name or not name.strip():\n+            raise ValueError(\"'name' may not be empty.\")\n+        \n         if \".\" in name:\n             raise ValueError(\"'name' may not contain a dot '.' character.\")\n \ndiff --git a/tests/test_blueprints.py b/tests/test_blueprints.py\nindex d46b769b..32bb9880 100644\n--- a/tests/test_blueprints.py\n+++ b/tests/test_blueprints.py\n@@ -256,6 +256,13 @@ def test_dotted_name_not_allowed(app, client):\n         flask.Blueprint(\"app.ui\", __name__)\n \n \n+def test_empty_name_not_allowed(app, client):\n+    with pytest.raises(ValueError):\n+        flask.Blueprint(\"\", __name__)\n+    with pytest.raises(ValueError):\n+        flask.Blueprint(\"   \", __name__)\n+\n+\n def test_dotted_names_from_app(app, client):\n     test = flask.Blueprint(\"test\", __name__)\n \n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "psf__requests-1142", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 9926045..9238e6f 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -358,10 +358,14 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             if files:\n                 raise NotImplementedError('Streamed bodies and files are mutually exclusive.')\n \n-            if length:\n-                self.headers['Content-Length'] = length\n+            if length and length != 'None':\n+                # Only set Content-Length for methods that can have a body\n+                if self.method not in ('GET', 'HEAD', 'OPTIONS'):\n+                    self.headers['Content-Length'] = length\n             else:\n-                self.headers['Transfer-Encoding'] = 'chunked'\n+                # Only set Transfer-Encoding for methods that can have a body\n+                if self.method not in ('GET', 'HEAD', 'OPTIONS'):\n+                    self.headers['Transfer-Encoding'] = 'chunked'\n         # Check if file, fo, generator, iterator.\n         # If not, run through normal process.\n \n@@ -377,7 +381,9 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n                     else:\n                         content_type = 'application/x-www-form-urlencoded'\n \n-            self.prepare_content_length(body)\n+            # Only set Content-Length for methods that can have a body\n+            if self.method not in ('GET', 'HEAD', 'OPTIONS'):\n+                self.prepare_content_length(body)\n \n             # Add content-type if it wasn't explicitly provided.\n             if (content_type) and (not 'content-type' in self.headers):\n@@ -386,13 +392,14 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         self.body = body\n \n     def prepare_content_length(self, body):\n-        self.headers['Content-Length'] = '0'\n-        if hasattr(body, 'seek') and hasattr(body, 'tell'):\n-            body.seek(0, 2)\n-            self.headers['Content-Length'] = str(body.tell())\n-            body.seek(0, 0)\n-        elif body is not None:\n-            self.headers['Content-Length'] = str(len(body))\n+        if body is not None:\n+            self.headers['Content-Length'] = '0'\n+            if hasattr(body, 'seek') and hasattr(body, 'tell'):\n+                body.seek(0, 2)\n+                self.headers['Content-Length'] = str(body.tell())\n+                body.seek(0, 0)\n+            else:\n+                self.headers['Content-Length'] = str(len(body))\n \n     def prepare_auth(self, auth):\n         \"\"\"Prepares the given HTTP auth data.\"\"\"\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "psf__requests-1724", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex f82f56a..6dba959 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -307,7 +307,8 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         \"\"\"Prepares the given HTTP method.\"\"\"\n         self.method = method\n         if self.method is not None:\n-            self.method = self.method.upper()\n+            # Convert to string first, then upper case, then to native string\n+            self.method = to_native_string(str(self.method).upper())\n \n     def prepare_url(self, url, params):\n         \"\"\"Prepares the given HTTP URL.\"\"\"\ndiff --git a/requests/sessions.py b/requests/sessions.py\nindex cc72f65..57ae31a 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -16,7 +16,7 @@ from .compat import cookielib, OrderedDict, urljoin, urlparse, urlunparse\n from .cookies import cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar\n from .models import Request, PreparedRequest\n from .hooks import default_hooks, dispatch_hook\n-from .utils import to_key_val_list, default_headers\n+from .utils import to_key_val_list, default_headers, to_native_string\n from .exceptions import TooManyRedirects, InvalidSchema\n from .structures import CaseInsensitiveDict\n \n@@ -311,7 +311,7 @@ class Session(SessionRedirectMixin):\n         \"\"\"\n         # Create the Request.\n         req = Request(\n-            method = method.upper(),\n+            method = to_native_string(str(method).upper()),\n             url = url,\n             headers = headers,\n             files = files,\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "psf__requests-1766", "model_patch": "diff --git a/requests/auth.py b/requests/auth.py\nindex a3de123..48416e5 100644\n--- a/requests/auth.py\n+++ b/requests/auth.py\n@@ -144,7 +144,7 @@ class HTTPDigestAuth(AuthBase):\n         if entdig:\n             base += ', digest=\"%s\"' % entdig\n         if qop:\n-            base += ', qop=auth, nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n+            base += ', qop=\"auth\", nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n \n         return 'Digest %s' % (base)\n \n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "psf__requests-1921", "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4e..4a9ac9e 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -54,10 +54,16 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     merged_setting = dict_class(to_key_val_list(session_setting))\n     merged_setting.update(to_key_val_list(request_setting))\n \n-    # Remove keys that are set to None.\n+    # Remove keys that are set to None in either request or session settings.\n     for (k, v) in request_setting.items():\n         if v is None:\n             del merged_setting[k]\n+    \n+    for (k, v) in session_setting.items():\n+        if v is None:\n+            # Only delete if not explicitly set in request\n+            if k not in request_setting:\n+                del merged_setting[k]\n \n     return merged_setting\n \n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "psf__requests-2317", "model_patch": ""}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "psf__requests-2931", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 9c624d3..0e5c3de 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -444,11 +444,15 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n                 (body, content_type) = self._encode_files(files, data)\n             else:\n                 if data:\n-                    body = self._encode_params(data)\n-                    if isinstance(data, basestring) or hasattr(data, 'read'):\n+                    if isinstance(data, bytes):\n+                        body = data\n                         content_type = None\n                     else:\n-                        content_type = 'application/x-www-form-urlencoded'\n+                        body = self._encode_params(data)\n+                        if isinstance(data, basestring) or hasattr(data, 'read'):\n+                            content_type = None\n+                        else:\n+                            content_type = 'application/x-www-form-urlencoded'\n \n             self.prepare_content_length(body)\n \n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "psf__requests-5414", "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex fe22ff45..36b0be17 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -28,6 +28,7 @@ from urllib3.exceptions import ReadTimeoutError\n from urllib3.exceptions import SSLError as _SSLError\n from urllib3.exceptions import ResponseError\n from urllib3.exceptions import LocationValueError\n+from urllib3.exceptions import LocationParseError\n \n from .models import Response\n from .compat import urlparse, basestring\n@@ -524,6 +525,9 @@ class HTTPAdapter(BaseAdapter):\n         except _ProxyError as e:\n             raise ProxyError(e)\n \n+        except LocationParseError as e:\n+            raise InvalidURL('URL has an invalid label.', request=request)\n+\n         except (_SSLError, _HTTPError) as e:\n             if isinstance(e, _SSLError):\n                 # This branch is for urllib3 versions earlier than v1.22\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "psf__requests-6028", "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex fe22ff45..ca04ba0f 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -178,6 +178,27 @@ class HTTPAdapter(BaseAdapter):\n         \"\"\"\n         if proxy in self.proxy_manager:\n             manager = self.proxy_manager[proxy]\n+            # Ensure proxy headers are up-to-date\n+            proxy_headers = self.proxy_headers(proxy)\n+            # Update proxy headers for HTTP/HTTPS proxies\n+            if hasattr(manager, 'proxy_headers'):\n+                manager.proxy_headers = proxy_headers\n+            # For SOCKS proxies, we might need to recreate the manager if auth changes\n+            elif proxy.lower().startswith('socks'):\n+                cached_username = getattr(manager, 'username', None)\n+                cached_password = getattr(manager, 'password', None)\n+                username, password = get_auth_from_url(proxy)\n+                if cached_username != username or cached_password != password:\n+                    # Recreate the manager with new credentials\n+                    manager = self.proxy_manager[proxy] = SOCKSProxyManager(\n+                        proxy,\n+                        username=username,\n+                        password=password,\n+                        num_pools=self._pool_connections,\n+                        maxsize=self._pool_maxsize,\n+                        block=self._pool_block,\n+                        **proxy_kwargs\n+                    )\n         elif proxy.lower().startswith('socks'):\n             username, password = get_auth_from_url(proxy)\n             manager = self.proxy_manager[proxy] = SOCKSProxyManager(\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-2905", "model_patch": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..87eda607 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -218,7 +218,13 @@ def as_compatible_data(data, fastpath=False):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n     # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+    # Only extract values from DataArray and Variable objects\n+    if hasattr(data, \"values\") and (hasattr(data, \"__class__\") and \n+                                    (data.__class__.__name__ in (\"DataArray\", \"Variable\") or\n+                                     (hasattr(data.__class__, \"__module__\") and \n+                                      data.__class__.__module__ is not None and\n+                                      \"xarray\" in data.__class__.__module__))):\n+        data = data.values\n \n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-3095", "model_patch": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 379be8f5..3f1bcfa6 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1947,7 +1947,9 @@ class IndexVariable(Variable):\n                 # point, which doesn't have a copy method, so make a deep copy\n                 # of the underlying `pandas.MultiIndex` and create a new\n                 # `PandasIndexAdapter` instance with it.\n-                data = PandasIndexAdapter(self._data.array.copy(deep=True))\n+                # Preserve the original dtype to avoid casting unicode to object\n+                data = PandasIndexAdapter(self._data.array.copy(deep=True), \n+                                          dtype=self._data.dtype)\n             else:\n                 data = self._data\n         else:\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-3151", "model_patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\nindex 37ae903b..9eab67e6 100644\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -501,7 +501,8 @@ def combine_by_coords(datasets, compat='no_conflicts', data_vars='all',\n                                    fill_value=fill_value)\n \n         # Check the overall coordinates are monotonically increasing\n-        for dim in concatenated.dims:\n+        # Only check dimensions that were actually concatenated (i.e., varied between datasets)\n+        for dim in concat_dims:\n             if dim in concatenated:\n                 indexes = concatenated.indexes.get(dim)\n                 if not (indexes.is_monotonic_increasing\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-3305", "model_patch": "diff --git a/reproduce_issue.py b/reproduce_issue.py\nnew file mode 100644\nindex 00000000..3ee7b371\n--- /dev/null\n+++ b/reproduce_issue.py\n@@ -0,0 +1,8 @@\n+import xarray as xr\n+\n+# Reproduce the issue\n+da = xr.DataArray([0, 0], dims=\"x\", attrs={'units':'K'})\n+out = da.quantile(.9, dim='x', keep_attrs=True)\n+print(\"Attributes:\", out.attrs)\n+print(\"Expected: OrderedDict([('units', 'K')])\")\n+print(\"Actual:\", out.attrs)\n\\ No newline at end of file\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-3677", "model_patch": "diff --git a/xarray/core/merge.py b/xarray/core/merge.py\nindex 10c7804d..c164c487 100644\n--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -809,6 +809,13 @@ def dataset_merge_method(\n     # method due for backwards compatibility\n     # TODO: consider deprecating it?\n \n+    from .dataarray import DataArray\n+    from .dataset import Dataset\n+\n+    # Convert DataArray to Dataset if needed\n+    if isinstance(other, DataArray):\n+        other = other.to_dataset()\n+\n     if isinstance(overwrite_vars, Iterable) and not isinstance(overwrite_vars, str):\n         overwrite_vars = set(overwrite_vars)\n     else:\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-3993", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 2fef3edb..33eb8040 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -3481,18 +3481,20 @@ class DataArray(AbstractArray, DataWithCoords):\n         return self._from_temp_dataset(ds)\n \n     def integrate(\n-        self, dim: Union[Hashable, Sequence[Hashable]], datetime_unit: str = None\n+        self, coord=None, dim=None, datetime_unit: str = None\n     ) -> \"DataArray\":\n         \"\"\" integrate the array with the trapezoidal rule.\n \n         .. note::\n-            This feature is limited to simple cartesian geometry, i.e. dim\n+            This feature is limited to simple cartesian geometry, i.e. coord\n             must be one dimensional.\n \n         Parameters\n         ----------\n-        dim : hashable, or sequence of hashable\n+        coord : hashable, or sequence of hashable\n             Coordinate(s) used for the integration.\n+        dim : hashable, or sequence of hashable, optional\n+            Deprecated. Use `coord` instead.\n         datetime_unit : {\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \\\n                          \"ps\", \"fs\", \"as\"}, optional\n             Can be used to specify the unit if datetime coordinate is used.\n@@ -3523,12 +3525,28 @@ class DataArray(AbstractArray, DataWithCoords):\n           * x        (x) float64 0.0 0.1 1.1 1.2\n         Dimensions without coordinates: y\n         >>>\n-        >>> da.integrate(\"x\")\n+        >>> da.integrate(coord=\"x\")\n         <xarray.DataArray (y: 3)>\n         array([5.4, 6.6, 7.8])\n         Dimensions without coordinates: y\n         \"\"\"\n-        ds = self._to_temp_dataset().integrate(dim, datetime_unit)\n+        # Handle deprecation of 'dim' parameter\n+        if dim is not None:\n+            import warnings\n+            warnings.warn(\n+                \"The `dim` parameter in DataArray.integrate is deprecated and will be removed \"\n+                \"in a future version. Please use `coord` instead.\",\n+                FutureWarning,\n+                stacklevel=2\n+            )\n+            if coord is not None:\n+                raise ValueError(\"Cannot specify both 'coord' and 'dim' parameters.\")\n+            coord = dim\n+        \n+        if coord is None:\n+            raise ValueError(\"Must specify 'coord' parameter.\")\n+            \n+        ds = self._to_temp_dataset().integrate(coord, datetime_unit)\n         return self._from_temp_dataset(ds)\n \n     def unify_chunks(self) -> \"DataArray\":\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-4075", "model_patch": "diff --git a/xarray/core/weighted.py b/xarray/core/weighted.py\nindex 996d2e4c..b99ce305 100644\n--- a/xarray/core/weighted.py\n+++ b/xarray/core/weighted.py\n@@ -142,7 +142,12 @@ class Weighted:\n         # we need to mask data values that are nan; else the weights are wrong\n         mask = da.notnull()\n \n-        sum_of_weights = self._reduce(mask, self.weights, dim=dim, skipna=False)\n+        # Convert weights to float to ensure correct calculation with boolean weights\n+        weights = self.weights\n+        if weights.dtype == bool:\n+            weights = weights * 1.0\n+\n+        sum_of_weights = self._reduce(mask, weights, dim=dim, skipna=False)\n \n         # 0-weights are not valid\n         valid_weights = sum_of_weights != 0.0\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-4094", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex b0df8749..eaa28e81 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1961,7 +1961,14 @@ class DataArray(AbstractArray, DataWithCoords):\n         # pull variables out of datarray\n         data_dict = {}\n         for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+            # Select the variable and drop the stacked coordinate\n+            selected = self.sel({variable_dim: k})\n+            squeezed = selected.squeeze(drop=True)\n+            # Drop the stacked coordinate that's not a dimension, if it exists\n+            if dim in squeezed.coords:\n+                data_dict[k] = squeezed.drop_vars(dim)\n+            else:\n+                data_dict[k] = squeezed\n \n         # unstacked dataset\n         return Dataset(data_dict)\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-4356", "model_patch": "diff --git a/xarray/core/nanops.py b/xarray/core/nanops.py\nindex 41c8d258..c6c6b817 100644\n--- a/xarray/core/nanops.py\n+++ b/xarray/core/nanops.py\n@@ -26,21 +26,42 @@ def _maybe_null_out(result, axis, mask, min_count=1):\n     \"\"\"\n     xarray version of pandas.core.nanops._maybe_null_out\n     \"\"\"\n-    if hasattr(axis, \"__len__\"):  # if tuple or list\n-        raise ValueError(\n-            \"min_count is not available for reduction with more than one dimensions.\"\n-        )\n-\n     if axis is not None and getattr(result, \"ndim\", False):\n-        null_mask = (mask.shape[axis] - mask.sum(axis) - min_count) < 0\n+        # Handle both single axis and multiple axes\n+        if hasattr(axis, \"__len__\"):  # if tuple or list\n+            # For multiple axes, calculate the product of the dimensions being reduced\n+            reduced_size = np.prod(np.take(mask.shape, axis))\n+            valid_count = reduced_size - mask.sum(axis=axis)\n+            null_mask = (valid_count - min_count) < 0\n+        else:\n+            # For single axis, use the original logic\n+            valid_count = mask.shape[axis] - mask.sum(axis)\n+            null_mask = (valid_count - min_count) < 0\n+        \n         if null_mask.any():\n             dtype, fill_value = dtypes.maybe_promote(result.dtype)\n             result = result.astype(dtype)\n             result[null_mask] = fill_value\n \n+    elif axis is not None:  # For scalar results (0-dimensional)\n+        # Handle both single axis and multiple axes for scalar results\n+        if hasattr(axis, \"__len__\"):  # if tuple or list\n+            # For multiple axes, calculate the product of the dimensions being reduced\n+            reduced_size = np.prod(np.take(mask.shape, axis))\n+            valid_count = reduced_size - mask.sum(axis=axis)\n+            null_mask = (valid_count - min_count) < 0\n+        else:\n+            # For single axis, use the original logic\n+            valid_count = mask.shape[axis] - mask.sum(axis)\n+            null_mask = (valid_count - min_count) < 0\n+        \n+        if null_mask:\n+            result = np.nan\n+\n     elif getattr(result, \"dtype\", None) not in dtypes.NAT_TYPES:\n-        null_mask = mask.size - mask.sum()\n-        if null_mask < min_count:\n+        valid_count = mask.size - mask.sum()\n+        null_mask = (valid_count - min_count) < 0\n+        if null_mask:\n             result = np.nan\n \n     return result\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-4629", "model_patch": "diff --git a/xarray/core/merge.py b/xarray/core/merge.py\nindex ca4e29b6..dff00804 100644\n--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -501,7 +501,7 @@ def merge_attrs(variable_attrs, combine_attrs):\n     if combine_attrs == \"drop\":\n         return {}\n     elif combine_attrs == \"override\":\n-        return variable_attrs[0]\n+        return dict(variable_attrs[0])\n     elif combine_attrs == \"no_conflicts\":\n         result = dict(variable_attrs[0])\n         for attrs in variable_attrs[1:]:\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-4687", "model_patch": "diff --git a/xarray/core/computation.py b/xarray/core/computation.py\nindex 9fe93c88..eb2fb675 100644\n--- a/xarray/core/computation.py\n+++ b/xarray/core/computation.py\n@@ -1727,7 +1727,7 @@ def dot(*arrays, dims=None, **kwargs):\n     return result.transpose(*all_dims, missing_dims=\"ignore\")\n \n \n-def where(cond, x, y):\n+def where(cond, x, y, keep_attrs=None):\n     \"\"\"Return elements from `x` or `y` depending on `cond`.\n \n     Performs xarray-like broadcasting across input arguments.\n@@ -1743,6 +1743,10 @@ def where(cond, x, y):\n         values to choose from where `cond` is True\n     y : scalar, array, Variable, DataArray or Dataset\n         values to choose from where `cond` is False\n+    keep_attrs : bool, optional\n+        If True, the attributes (``attrs``) will be copied from the first\n+        array to the new one. If False (default), the new object will be\n+        returned without attributes.\n \n     Returns\n     -------\n@@ -1809,7 +1813,10 @@ def where(cond, x, y):\n         equivalent methods\n     \"\"\"\n     # alignment for three arguments is complicated, so don't support it yet\n-    return apply_ufunc(\n+    if keep_attrs is None:\n+        keep_attrs = _get_keep_attrs(default=False)\n+        \n+    result = apply_ufunc(\n         duck_array_ops.where,\n         cond,\n         x,\n@@ -1817,7 +1824,19 @@ def where(cond, x, y):\n         join=\"exact\",\n         dataset_join=\"exact\",\n         dask=\"allowed\",\n+        keep_attrs=keep_attrs,\n     )\n+    \n+    # For where, we want to take attributes from the first DataArray argument\n+    # that has non-empty attributes if keep_attrs is True\n+    if keep_attrs:\n+        # Check all arguments for DataArrays with attributes\n+        for arg in [cond, x, y]:\n+            if hasattr(arg, \"attrs\") and arg.attrs:\n+                result.attrs = arg.attrs.copy()\n+                break\n+        \n+    return result\n \n \n def polyval(coord, coeffs, degree_dim=\"degree\"):\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-4695", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 32b24ef1..c16f39c9 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -196,7 +196,29 @@ class _LocIndexer:\n             # expand the indexer so we can handle Ellipsis\n             labels = indexing.expanded_indexer(key, self.data_array.ndim)\n             key = dict(zip(self.data_array.dims, labels))\n-        return self.data_array.sel(**key)\n+        \n+        # Handle the case where a dimension name conflicts with a parameter name\n+        # For example, if we have a dimension named \"method\", we need to pass it\n+        # as a positional argument to avoid conflict with the method parameter\n+        sel_kwargs = {}\n+        sel_indexers = {}\n+        for k, v in key.items():\n+            if k in [\"method\", \"tolerance\", \"drop\"]:\n+                # These are parameter names of the sel method\n+                if k in self.data_array.dims:\n+                    # This is actually a dimension name, so we need to pass it as an indexer\n+                    sel_indexers[k] = v\n+                else:\n+                    # This is actually a parameter, so we pass it as a keyword argument\n+                    sel_kwargs[k] = v\n+            else:\n+                # This is not a parameter name, so we pass it as an indexer\n+                sel_indexers[k] = v\n+        \n+        if sel_indexers:\n+            return self.data_array.sel(indexers=sel_indexers, **sel_kwargs)\n+        else:\n+            return self.data_array.sel(**sel_kwargs)\n \n     def __setitem__(self, key, value) -> None:\n         if not utils.is_dict_like(key):\ndiff --git a/xarray/core/indexing.py b/xarray/core/indexing.py\nindex 843feb04..45102ae4 100644\n--- a/xarray/core/indexing.py\n+++ b/xarray/core/indexing.py\n@@ -105,7 +105,7 @@ def get_indexer_nd(index, labels, method=None, tolerance=None):\n     return indexer\n \n \n-def convert_label_indexer(index, label, index_name=\"\", method=None, tolerance=None):\n+def convert_label_indexer(index, label, index_name=\"\", indexer_method=None, tolerance=None):\n     \"\"\"Given a pandas.Index and labels (e.g., from __getitem__) for one\n     dimension, return an indexer suitable for indexing an ndarray along that\n     dimension. If `index` is a pandas.MultiIndex and depending on `label`,\n@@ -114,7 +114,7 @@ def convert_label_indexer(index, label, index_name=\"\", method=None, tolerance=No\n     new_index = None\n \n     if isinstance(label, slice):\n-        if method is not None or tolerance is not None:\n+        if indexer_method is not None or tolerance is not None:\n             raise NotImplementedError(\n                 \"cannot use ``method`` argument if any indexers are slice objects\"\n             )\n@@ -178,7 +178,7 @@ def convert_label_indexer(index, label, index_name=\"\", method=None, tolerance=No\n             if isinstance(index, pd.MultiIndex):\n                 indexer, new_index = index.get_loc_level(label_value, level=0)\n             elif isinstance(index, pd.CategoricalIndex):\n-                if method is not None:\n+                if indexer_method is not None:\n                     raise ValueError(\n                         \"'method' is not a valid kwarg when indexing using a CategoricalIndex.\"\n                     )\n@@ -188,7 +188,7 @@ def convert_label_indexer(index, label, index_name=\"\", method=None, tolerance=No\n                     )\n                 indexer = index.get_loc(label_value)\n             else:\n-                indexer = index.get_loc(label_value, method=method, tolerance=tolerance)\n+                indexer = index.get_loc(label_value, method=indexer_method, tolerance=tolerance)\n         elif label.dtype.kind == \"b\":\n             indexer = label\n         else:\n@@ -197,7 +197,7 @@ def convert_label_indexer(index, label, index_name=\"\", method=None, tolerance=No\n                     \"Vectorized selection is not available along \"\n                     \"MultiIndex variable: \" + index_name\n                 )\n-            indexer = get_indexer_nd(index, label, method, tolerance)\n+            indexer = get_indexer_nd(index, label, indexer_method, tolerance)\n             if np.any(indexer < 0):\n                 raise KeyError(f\"not all values found in index {index_name!r}\")\n     return indexer, new_index\n@@ -267,7 +267,7 @@ def remap_label_indexers(data_obj, indexers, method=None, tolerance=None):\n         else:\n             coords_dtype = data_obj.coords[dim].dtype\n             label = maybe_cast_to_coords_dtype(label, coords_dtype)\n-            idxr, new_idx = convert_label_indexer(index, label, dim, method, tolerance)\n+            idxr, new_idx = convert_label_indexer(index, label, dim, indexer_method=method, tolerance=tolerance)\n             pos_indexers[dim] = idxr\n             if new_idx is not None:\n                 new_indexes[dim] = new_idx\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-4966", "model_patch": "diff --git a/xarray/coding/variables.py b/xarray/coding/variables.py\nindex b035ff82..938752c4 100644\n--- a/xarray/coding/variables.py\n+++ b/xarray/coding/variables.py\n@@ -316,6 +316,14 @@ class UnsignedIntegerCoder(VariableCoder):\n                     if \"_FillValue\" in attrs:\n                         new_fill = unsigned_dtype.type(attrs[\"_FillValue\"])\n                         attrs[\"_FillValue\"] = new_fill\n+            elif data.dtype.kind == \"u\":\n+                if unsigned == \"false\":\n+                    signed_dtype = np.dtype(\"i%s\" % data.dtype.itemsize)\n+                    transform = partial(np.asarray, dtype=signed_dtype)\n+                    data = lazy_elemwise_func(data, transform, signed_dtype)\n+                    if \"_FillValue\" in attrs:\n+                        new_fill = signed_dtype.type(attrs[\"_FillValue\"])\n+                        attrs[\"_FillValue\"] = new_fill\n             else:\n                 warnings.warn(\n                     \"variable %r has _Unsigned attribute but is not \"\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-6461", "model_patch": "diff --git a/xarray/core/computation.py b/xarray/core/computation.py\nindex 7676d8e5..885c1b51 100644\n--- a/xarray/core/computation.py\n+++ b/xarray/core/computation.py\n@@ -1829,7 +1829,7 @@ def where(cond, x, y, keep_attrs=None):\n     if keep_attrs is True:\n         # keep the attributes of x, the second parameter, by default to\n         # be consistent with the `where` method of `DataArray` and `Dataset`\n-        keep_attrs = lambda attrs, context: attrs[1]\n+        keep_attrs = lambda attrs, context: attrs[1] if len(attrs) > 1 else {}\n \n     # alignment for three arguments is complicated, so don't support it yet\n     return apply_ufunc(\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-6599", "model_patch": "diff --git a/xarray/core/computation.py b/xarray/core/computation.py\nindex 823cbe02..cb8aba70 100644\n--- a/xarray/core/computation.py\n+++ b/xarray/core/computation.py\n@@ -1892,6 +1892,7 @@ def polyval(\n     xarray.DataArray.polyfit\n     numpy.polynomial.polynomial.polyval\n     \"\"\"\n+    from .dataarray import DataArray\n \n     if degree_dim not in coeffs._indexes:\n         raise ValueError(\n@@ -1905,20 +1906,47 @@ def polyval(\n     coeffs = coeffs.reindex(\n         {degree_dim: np.arange(max_deg + 1)}, fill_value=0, copy=False\n     )\n-    coord = _ensure_numeric(coord)  # type: ignore # https://github.com/python/mypy/issues/1533 ?\n+    \n+    # Extract coordinate values for evaluation while preserving original coordinates\n+    original_coords = None\n+    if isinstance(coord, DataArray):\n+        # For DataArray, use the coordinate values, not the data values\n+        if len(coord.dims) == 1:\n+            dim_name = coord.dims[0]\n+            if dim_name in coord.coords:\n+                # Store original coordinates to preserve them in the result\n+                original_coords = {dim_name: coord.coords[dim_name]}\n+                # Use the coordinate values for this dimension for computation\n+                coord_values = coord.coords[dim_name]\n+                # Apply numeric conversion to coordinate values for computation\n+                coord_for_computation = _ensure_numeric(coord_values)\n+            else:\n+                # Fallback to using the data values\n+                coord_for_computation = _ensure_numeric(coord)\n+        else:\n+            # For multi-dimensional DataArrays, use the data values\n+            coord_for_computation = _ensure_numeric(coord)\n+    else:\n+        # For Dataset or already processed coordinates, apply numeric conversion\n+        coord_for_computation = _ensure_numeric(coord)\n+        coord = coord_for_computation\n \n     # using Horner's method\n     # https://en.wikipedia.org/wiki/Horner%27s_method\n-    res = coeffs.isel({degree_dim: max_deg}, drop=True) + zeros_like(coord)\n+    res = coeffs.isel({degree_dim: max_deg}, drop=True) + zeros_like(coord_for_computation)\n     for deg in range(max_deg - 1, -1, -1):\n-        res *= coord\n+        res *= coord_for_computation\n         res += coeffs.isel({degree_dim: deg}, drop=True)\n \n+    # Restore original coordinates if we modified them\n+    if original_coords is not None and isinstance(res, DataArray):\n+        res = res.assign_coords(original_coords)\n+\n     return res\n \n \n def _ensure_numeric(data: T_Xarray) -> T_Xarray:\n-    \"\"\"Converts all datetime64 variables to float64\n+    \"\"\"Converts all datetime64 and timedelta64 variables to float64\n \n     Parameters\n     ----------\n@@ -1928,12 +1956,13 @@ def _ensure_numeric(data: T_Xarray) -> T_Xarray:\n     Returns\n     -------\n     DataArray or Dataset\n-        Variables with datetime64 dtypes converted to float64.\n+        Variables with datetime64/timedelta64 dtypes converted to float64.\n     \"\"\"\n     from .dataset import Dataset\n+    from .dataarray import DataArray\n \n     def to_floatable(x: DataArray) -> DataArray:\n-        if x.dtype.kind in \"mM\":\n+        if x.dtype.kind == \"M\":  # datetime64\n             return x.copy(\n                 data=datetime_to_numeric(\n                     x.data,\n@@ -1941,10 +1970,27 @@ def _ensure_numeric(data: T_Xarray) -> T_Xarray:\n                     datetime_unit=\"ns\",\n                 ),\n             )\n+        elif x.dtype.kind == \"m\":  # timedelta64\n+            # For timedelta64, convert directly to numeric without offset\n+            data = x.data\n+            if data.dtype != np.dtype('timedelta64[ns]'):\n+                # Convert to nanoseconds if needed\n+                data = data / np.timedelta64(1, 'ns')\n+            return x.copy(data=data.astype(float))\n         return x\n \n     if isinstance(data, Dataset):\n         return data.map(to_floatable)\n+    elif isinstance(data, DataArray):\n+        # Process the data variable\n+        result = to_floatable(data)\n+        # Also process the coordinates\n+        new_coords = {}\n+        for name, coord in result.coords.items():\n+            new_coords[name] = to_floatable(coord)\n+        if new_coords:\n+            result = result.assign_coords(new_coords)\n+        return result\n     else:\n         return to_floatable(data)\n \n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-6721", "model_patch": "diff --git a/xarray/core/common.py b/xarray/core/common.py\nindex 3c328f42..c1283b70 100644\n--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -2023,8 +2023,10 @@ def get_chunksizes(\n \n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.data, \"chunks\"):\n-            for dim, c in v.chunksizes.items():\n+        # Use the chunksizes property which handles different data types correctly\n+        var_chunks = v.chunksizes\n+        if var_chunks:  # Only process if there are chunks\n+            for dim, c in var_chunks.items():\n                 if dim in chunks and c != chunks[dim]:\n                     raise ValueError(\n                         f\"Object has inconsistent chunks along dimension {dim}. \"\ndiff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 2d115ff0..ceaf1aea 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1014,6 +1014,21 @@ class Variable(AbstractArray, NdimSizeLenMixin, VariableArithmetic):\n         Variable.chunks\n         xarray.unify_chunks\n         \"\"\"\n+        # Check if we have encoding with chunks information (e.g., for zarr arrays)\n+        if \"chunks\" in self.encoding and self.encoding[\"chunks\"] is not None:\n+            chunks = self.encoding[\"chunks\"]\n+            # Handle different types of chunks in encoding:\n+            # 1. Integer: same chunk size for all dimensions\n+            # 2. Tuple: explicit chunk sizes for each dimension\n+            if isinstance(chunks, int):\n+                # Same chunk size for all dimensions\n+                return Frozen({dim: chunks for dim in self.dims})\n+            elif isinstance(chunks, (tuple, list)):\n+                # Explicit chunk sizes for each dimension\n+                return Frozen({dim: c for dim, c in zip(self.dims, chunks)})\n+            else:\n+                # Unexpected type, fall back to default behavior\n+                pass\n         if hasattr(self._data, \"chunks\"):\n             return Frozen({dim: c for dim, c in zip(self.dims, self.data.chunks)})\n         else:\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-6744", "model_patch": "diff --git a/xarray/core/rolling.py b/xarray/core/rolling.py\nindex aef290f6..340d1cf5 100644\n--- a/xarray/core/rolling.py\n+++ b/xarray/core/rolling.py\n@@ -270,9 +270,28 @@ class DataArrayRolling(Rolling[\"DataArray\"]):\n     def __iter__(self) -> Iterator[tuple[RollingKey, DataArray]]:\n         if self.ndim > 1:\n             raise ValueError(\"__iter__ is only supported for 1d-rolling\")\n-        stops = np.arange(1, len(self.window_labels) + 1)\n-        starts = stops - int(self.window[0])\n-        starts[: int(self.window[0])] = 0\n+        \n+        # Handle centering\n+        if self.center[0]:\n+            # For centered windows, we need to adjust the start and stop indices\n+            # to center the window around each label\n+            window_size = int(self.window[0])\n+            half_window = window_size // 2\n+            \n+            # Calculate the start and stop indices for centered windows\n+            indices = np.arange(len(self.window_labels))\n+            starts = indices - half_window\n+            stops = indices + half_window + (window_size % 2)  # Add 1 for odd-sized windows\n+            \n+            # Handle edge cases where windows extend beyond the array bounds\n+            starts = np.maximum(starts, 0)\n+            stops = np.minimum(stops, len(self.window_labels))\n+        else:\n+            # Original logic for non-centered windows\n+            stops = np.arange(1, len(self.window_labels) + 1)\n+            starts = stops - int(self.window[0])\n+            starts[: int(self.window[0])] = 0\n+            \n         for (label, start, stop) in zip(self.window_labels, starts, stops):\n             window = self.obj.isel({self.dim[0]: slice(start, stop)})\n \n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-6938", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex c775d05c..681de65e 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3772,7 +3772,7 @@ class Dataset(\n         for k, v in self.variables.items():\n             dims = tuple(dims_dict.get(dim, dim) for dim in v.dims)\n             if k in result_dims:\n-                var = v.to_index_variable()\n+                var = v.copy(deep=False)\n                 var.dims = dims\n                 if k in self._indexes:\n                     indexes[k] = self._indexes[k]\n@@ -3783,7 +3783,7 @@ class Dataset(\n                     variables.update(index_vars)\n                     coord_names.update(index_vars)\n             else:\n-                var = v.to_base_variable()\n+                var = v.copy(deep=False)\n                 var.dims = dims\n                 variables[k] = var\n \n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-6992", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 620f32f8..4e9ea060 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -365,7 +365,11 @@ class DataVariables(Mapping[Any, \"DataArray\"]):\n         )\n \n     def __len__(self) -> int:\n-        return len(self._dataset._variables) - len(self._dataset._coord_names)\n+        count = 0\n+        for key in self._dataset._variables:\n+            if key not in self._dataset._coord_names:\n+                count += 1\n+        return count\n \n     def __contains__(self, key: Hashable) -> bool:\n         return key in self._dataset._variables and key not in self._dataset._coord_names\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-7229", "model_patch": "diff --git a/reproduce_issue.py b/reproduce_issue.py\nnew file mode 100644\nindex 00000000..9d027844\n--- /dev/null\n+++ b/reproduce_issue.py\n@@ -0,0 +1,23 @@\n+import xarray as xr\n+\n+# Load the tutorial dataset\n+ds = xr.tutorial.load_dataset(\"air_temperature\")\n+\n+# Print the original time attributes\n+print(\"Original time attributes:\")\n+print(ds.time.attrs)\n+\n+# Apply xr.where with keep_attrs=True\n+result = xr.where(True, ds.air, ds.air, keep_attrs=True)\n+\n+# Print the time attributes after applying xr.where\n+print(\"\\nTime attributes after xr.where:\")\n+print(result.time.attrs)\n+\n+# Check if the attributes are the same\n+if ds.time.attrs == result.time.attrs:\n+    print(\"\\nSUCCESS: Coordinate attributes are preserved!\")\n+else:\n+    print(\"\\nERROR: Coordinate attributes are overwritten!\")\n+    print(\"Expected:\", ds.time.attrs)\n+    print(\"Got:\", result.time.attrs)\n\\ No newline at end of file\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-7233", "model_patch": "diff --git a/xarray/core/rolling.py b/xarray/core/rolling.py\nindex c194ec08..fb5b2bbb 100644\n--- a/xarray/core/rolling.py\n+++ b/xarray/core/rolling.py\n@@ -973,7 +973,8 @@ class Coarsen(CoarsenArithmetic, Generic[T_Xarray]):\n             else:\n                 reshaped[key] = var\n \n-        should_be_coords = set(window_dim) & set(self.obj.coords)\n+        # Preserve all coordinates from the original dataset\n+        should_be_coords = set(obj.coords)\n         result = reshaped.set_coords(should_be_coords)\n         if isinstance(self.obj, DataArray):\n             return self.obj._from_temp_dataset(result)\n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pydata__xarray-7393", "model_patch": "diff --git a/xarray/core/indexing.py b/xarray/core/indexing.py\nindex ba937183..3abb0c85 100644\n--- a/xarray/core/indexing.py\n+++ b/xarray/core/indexing.py\n@@ -1532,7 +1532,10 @@ class PandasMultiIndexingAdapter(PandasIndexingAdapter):\n \n     def __array__(self, dtype: DTypeLike = None) -> np.ndarray:\n         if self.level is not None:\n-            return self.array.get_level_values(self.level).values\n+            level_values = self.array.get_level_values(self.level).values\n+            if dtype is None:\n+                dtype = self.dtype\n+            return np.asarray(level_values, dtype=dtype)\n         else:\n             return super().__array__(dtype)\n \n"}
{"model_name_or_path": "openrouter_qwen_qwen3-coder", "instance_id": "pylint-dev__pylint-4551", "model_patch": "diff --git a/pylint/pyreverse/diagrams.py b/pylint/pyreverse/diagrams.py\nindex bf9f67af..72aff5da 100644\n--- a/pylint/pyreverse/diagrams.py\n+++ b/pylint/pyreverse/diagrams.py\n@@ -84,6 +84,29 @@ class ClassDiagram(Figure, FilterMixIn):\n             for n, m in node.items()\n             if isinstance(m, astroid.FunctionDef) and decorated_with_property(m)\n         ]\n+        \n+        # Get type annotations for __init__ method parameters\n+        param_annotations = {}\n+        init_method = node.locals.get('__init__', [None])[0]\n+        if init_method and hasattr(init_method, 'args') and init_method.args:\n+            # Use the annotations attribute of the Arguments node\n+            annotations = getattr(init_method.args, 'annotations', [])\n+            for i, arg in enumerate(init_method.args.args):\n+                if i < len(annotations) and annotations[i]:\n+                    try:\n+                        inferred_types = list(annotations[i].infer())\n+                        type_names = []\n+                        for inferred_type in inferred_types:\n+                            if hasattr(inferred_type, 'name'):\n+                                type_names.append(inferred_type.name)\n+                            elif hasattr(inferred_type, 'qname'):\n+                                type_names.append(inferred_type.qname().split('.')[-1])\n+                            else:\n+                                type_names.append(str(inferred_type))\n+                        param_annotations[arg.name] = \", \".join(type_names)\n+                    except astroid.InferenceError:\n+                        pass\n+        \n         for node_name, associated_nodes in (\n             list(node.instance_attrs_type.items())\n             + list(node.locals_type.items())\n@@ -91,9 +114,14 @@ class ClassDiagram(Figure, FilterMixIn):\n         ):\n             if not self.show_attr(node_name):\n                 continue\n-            names = self.class_names(associated_nodes)\n-            if names:\n-                node_name = \"{} : {}\".format(node_name, \", \".join(names))\n+            \n+            # Check if this is an instance attribute that corresponds to an __init__ parameter with type annotation\n+            if node_name in param_annotations:\n+                node_name = \"{} : {}\".format(node_name, param_annotations[node_name])\n+            else:\n+                names = self.class_names(associated_nodes)\n+                if names:\n+                    node_name = \"{} : {}\".format(node_name, \", \".join(names))\n             attrs.append(node_name)\n         return sorted(attrs)\n \n"}
