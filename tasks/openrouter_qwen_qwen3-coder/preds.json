{
    "pydata__xarray-6938": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pydata__xarray-6938",
        "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex c775d05c..681de65e 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3772,7 +3772,7 @@ class Dataset(\n         for k, v in self.variables.items():\n             dims = tuple(dims_dict.get(dim, dim) for dim in v.dims)\n             if k in result_dims:\n-                var = v.to_index_variable()\n+                var = v.copy(deep=False)\n                 var.dims = dims\n                 if k in self._indexes:\n                     indexes[k] = self._indexes[k]\n@@ -3783,7 +3783,7 @@ class Dataset(\n                     variables.update(index_vars)\n                     coord_names.update(index_vars)\n             else:\n-                var = v.to_base_variable()\n+                var = v.copy(deep=False)\n                 var.dims = dims\n                 variables[k] = var\n \n"
    },
    "pydata__xarray-6992": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pydata__xarray-6992",
        "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 620f32f8..4e9ea060 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -365,7 +365,11 @@ class DataVariables(Mapping[Any, \"DataArray\"]):\n         )\n \n     def __len__(self) -> int:\n-        return len(self._dataset._variables) - len(self._dataset._coord_names)\n+        count = 0\n+        for key in self._dataset._variables:\n+            if key not in self._dataset._coord_names:\n+                count += 1\n+        return count\n \n     def __contains__(self, key: Hashable) -> bool:\n         return key in self._dataset._variables and key not in self._dataset._coord_names\n"
    },
    "pydata__xarray-7229": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pydata__xarray-7229",
        "model_patch": "diff --git a/reproduce_issue.py b/reproduce_issue.py\nnew file mode 100644\nindex 00000000..9d027844\n--- /dev/null\n+++ b/reproduce_issue.py\n@@ -0,0 +1,23 @@\n+import xarray as xr\n+\n+# Load the tutorial dataset\n+ds = xr.tutorial.load_dataset(\"air_temperature\")\n+\n+# Print the original time attributes\n+print(\"Original time attributes:\")\n+print(ds.time.attrs)\n+\n+# Apply xr.where with keep_attrs=True\n+result = xr.where(True, ds.air, ds.air, keep_attrs=True)\n+\n+# Print the time attributes after applying xr.where\n+print(\"\\nTime attributes after xr.where:\")\n+print(result.time.attrs)\n+\n+# Check if the attributes are the same\n+if ds.time.attrs == result.time.attrs:\n+    print(\"\\nSUCCESS: Coordinate attributes are preserved!\")\n+else:\n+    print(\"\\nERROR: Coordinate attributes are overwritten!\")\n+    print(\"Expected:\", ds.time.attrs)\n+    print(\"Got:\", result.time.attrs)\n\\ No newline at end of file\n"
    },
    "pydata__xarray-7233": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pydata__xarray-7233",
        "model_patch": "diff --git a/xarray/core/rolling.py b/xarray/core/rolling.py\nindex c194ec08..fb5b2bbb 100644\n--- a/xarray/core/rolling.py\n+++ b/xarray/core/rolling.py\n@@ -973,7 +973,8 @@ class Coarsen(CoarsenArithmetic, Generic[T_Xarray]):\n             else:\n                 reshaped[key] = var\n \n-        should_be_coords = set(window_dim) & set(self.obj.coords)\n+        # Preserve all coordinates from the original dataset\n+        should_be_coords = set(obj.coords)\n         result = reshaped.set_coords(should_be_coords)\n         if isinstance(self.obj, DataArray):\n             return self.obj._from_temp_dataset(result)\n"
    },
    "pydata__xarray-7393": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pydata__xarray-7393",
        "model_patch": "diff --git a/xarray/core/indexing.py b/xarray/core/indexing.py\nindex ba937183..3abb0c85 100644\n--- a/xarray/core/indexing.py\n+++ b/xarray/core/indexing.py\n@@ -1532,7 +1532,10 @@ class PandasMultiIndexingAdapter(PandasIndexingAdapter):\n \n     def __array__(self, dtype: DTypeLike = None) -> np.ndarray:\n         if self.level is not None:\n-            return self.array.get_level_values(self.level).values\n+            level_values = self.array.get_level_values(self.level).values\n+            if dtype is None:\n+                dtype = self.dtype\n+            return np.asarray(level_values, dtype=dtype)\n         else:\n             return super().__array__(dtype)\n \n"
    },
    "pylint-dev__pylint-4551": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pylint-dev__pylint-4551",
        "model_patch": "diff --git a/pylint/pyreverse/diagrams.py b/pylint/pyreverse/diagrams.py\nindex bf9f67af..72aff5da 100644\n--- a/pylint/pyreverse/diagrams.py\n+++ b/pylint/pyreverse/diagrams.py\n@@ -84,6 +84,29 @@ class ClassDiagram(Figure, FilterMixIn):\n             for n, m in node.items()\n             if isinstance(m, astroid.FunctionDef) and decorated_with_property(m)\n         ]\n+        \n+        # Get type annotations for __init__ method parameters\n+        param_annotations = {}\n+        init_method = node.locals.get('__init__', [None])[0]\n+        if init_method and hasattr(init_method, 'args') and init_method.args:\n+            # Use the annotations attribute of the Arguments node\n+            annotations = getattr(init_method.args, 'annotations', [])\n+            for i, arg in enumerate(init_method.args.args):\n+                if i < len(annotations) and annotations[i]:\n+                    try:\n+                        inferred_types = list(annotations[i].infer())\n+                        type_names = []\n+                        for inferred_type in inferred_types:\n+                            if hasattr(inferred_type, 'name'):\n+                                type_names.append(inferred_type.name)\n+                            elif hasattr(inferred_type, 'qname'):\n+                                type_names.append(inferred_type.qname().split('.')[-1])\n+                            else:\n+                                type_names.append(str(inferred_type))\n+                        param_annotations[arg.name] = \", \".join(type_names)\n+                    except astroid.InferenceError:\n+                        pass\n+        \n         for node_name, associated_nodes in (\n             list(node.instance_attrs_type.items())\n             + list(node.locals_type.items())\n@@ -91,9 +114,14 @@ class ClassDiagram(Figure, FilterMixIn):\n         ):\n             if not self.show_attr(node_name):\n                 continue\n-            names = self.class_names(associated_nodes)\n-            if names:\n-                node_name = \"{} : {}\".format(node_name, \", \".join(names))\n+            \n+            # Check if this is an instance attribute that corresponds to an __init__ parameter with type annotation\n+            if node_name in param_annotations:\n+                node_name = \"{} : {}\".format(node_name, param_annotations[node_name])\n+            else:\n+                names = self.class_names(associated_nodes)\n+                if names:\n+                    node_name = \"{} : {}\".format(node_name, \", \".join(names))\n             attrs.append(node_name)\n         return sorted(attrs)\n \n"
    },
    "pylint-dev__pylint-4604": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pylint-dev__pylint-4604",
        "model_patch": "diff --git a/pylint/checkers/variables.py b/pylint/checkers/variables.py\nindex 3ddafd59..dfba536c 100644\n--- a/pylint/checkers/variables.py\n+++ b/pylint/checkers/variables.py\n@@ -1826,6 +1826,19 @@ class VariablesChecker(BaseChecker):\n             self._type_annotation_names.append(type_annotation.name)\n             return\n \n+        if isinstance(type_annotation, astroid.Attribute):\n+            # For attribute nodes like abc.ABC, we need to store all parts of the chain\n+            # For a.b.C, we need to store 'a', 'b', and 'C'\n+            current = type_annotation\n+            while isinstance(current, astroid.Attribute):\n+                # Store the attribute name (e.g., 'C' in a.b.C)\n+                self._type_annotation_names.append(current.attrname)\n+                current = current.expr\n+            # Store the final name (e.g., 'a' in a.b.C)\n+            if isinstance(current, astroid.Name):\n+                self._type_annotation_names.append(current.name)\n+            return\n+\n         if not isinstance(type_annotation, astroid.Subscript):\n             return\n \n"
    },
    "pylint-dev__pylint-4661": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pylint-dev__pylint-4661",
        "model_patch": "diff --git a/pylint/config/__init__.py b/pylint/config/__init__.py\nindex 84774d0e..31553f18 100644\n--- a/pylint/config/__init__.py\n+++ b/pylint/config/__init__.py\n@@ -63,7 +63,11 @@ if \"PYLINTHOME\" in os.environ:\n elif USER_HOME == \"~\":\n     PYLINT_HOME = \".pylint.d\"\n else:\n-    PYLINT_HOME = os.path.join(USER_HOME, \".pylint.d\")\n+    # XDG Base Directory Specification compliant path\n+    xdg_data_home = os.environ.get(\"XDG_DATA_HOME\")\n+    if not xdg_data_home:\n+        xdg_data_home = os.path.join(USER_HOME, \".local\", \"share\")\n+    PYLINT_HOME = os.path.join(xdg_data_home, \"pylint\")\n \n \n def _get_pdata_path(base_name, recurs):\n@@ -110,7 +114,7 @@ ENV_HELP = (\n The following environment variables are used:\n     * PYLINTHOME\n     Path to the directory where persistent data for the run will be stored. If\n-not found, it defaults to ~/.pylint.d/ or .pylint.d (in the current working\n+not found, it defaults to ~/.local/share/pylint/ or .pylint.d (in the current working\n directory).\n     * PYLINTRC\n     Path to the configuration file. See the documentation for the method used\n"
    },
    "pylint-dev__pylint-4970": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pylint-dev__pylint-4970",
        "model_patch": "diff --git a/debug_test.py b/debug_test.py\nnew file mode 100644\nindex 00000000..7aca3328\n--- /dev/null\n+++ b/debug_test.py\n@@ -0,0 +1,95 @@\n+#!/usr/bin/env python3\n+\n+\"\"\"\n+Script to debug the issue with min-similarity-lines=1\n+\"\"\"\n+\n+import tempfile\n+import os\n+from pylint.lint import PyLinter\n+from pylint.checkers import similar\n+from pylint.testutils import GenericTestReporter as Reporter\n+\n+def debug_min_similarity_lines():\n+    \"\"\"Debug what happens with min-similarity-lines=1\"\"\"\n+    # Create two identical files with more content\n+    content = \"\"\"\n+def func1():\n+    # This is a comment\n+    x = 1\n+    y = 2\n+    z = 3\n+    a = 4\n+    b = 5\n+    c = 6\n+    return x + y + z + a + b + c\n+\n+def func2():\n+    # This is a comment\n+    x = 1\n+    y = 2\n+    z = 3\n+    a = 4\n+    b = 5\n+    c = 6\n+    return x + y + z + a + b + c\n+\"\"\"\n+    \n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f1:\n+        f1.write(content)\n+        file1 = f1.name\n+    \n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f2:\n+        f2.write(content)\n+        file2 = f2.name\n+    \n+    try:\n+        # Test with min-similarity-lines=1\n+        print(\"Testing with min-similarity-lines=1:\")\n+        linter = PyLinter(reporter=Reporter())\n+        checker = similar.SimilarChecker(linter)\n+        linter.register_checker(checker)\n+        print(f\"Before set_option: checker.min_lines = {checker.min_lines}\")\n+        print(f\"Before set_option: checker.config.min_similarity_lines = {checker.config.min_similarity_lines}\")\n+        checker.set_option(\"min-similarity-lines\", 1)\n+        print(f\"After set_option: checker.min_lines = {checker.min_lines}\")\n+        print(f\"After set_option: checker.config.min_similarity_lines = {checker.config.min_similarity_lines}\")\n+        \n+        # Check the files\n+        linter.check([file1, file2])\n+        \n+        # Check if any duplicate code messages were reported\n+        print(f\"DEBUG: Reporter has {len(linter.reporter.messages)} messages\")\n+        for i, msg in enumerate(linter.reporter.messages):\n+            print(f\"DEBUG: Message {i}: {msg}\")\n+        messages = linter.reporter.messages\n+        duplicate_messages = [msg for msg in messages if \"Similar lines\" in str(msg)]\n+        \n+        print(f\"Number of duplicate-code messages: {len(duplicate_messages)}\")\n+        for msg in duplicate_messages:\n+            print(f\"Message: {msg}\")\n+            \n+        # Let's also check the internal state\n+        print(f\"Checker min_lines: {checker.min_lines}\")\n+        print(f\"Number of linesets: {len(checker.linesets)}\")\n+        if len(checker.linesets) >= 2:\n+            print(f\"Lineset 1 length: {len(checker.linesets[0])}\")\n+            print(f\"Lineset 2 length: {len(checker.linesets[1])}\")\n+            \n+        # Let's see what _compute_sims returns\n+        sims = checker._compute_sims()\n+        print(f\"Number of similarities found: {len(sims)}\")\n+        for num, couples in sims:\n+            print(f\"Similarity with {num} lines:\")\n+            for lineset, start, end in couples:\n+                print(f\"  File: {lineset.name}, lines {start}-{end}\")\n+            \n+        return True\n+            \n+    finally:\n+        # Clean up temporary files\n+        os.unlink(file1)\n+        os.unlink(file2)\n+\n+if __name__ == \"__main__\":\n+    debug_min_similarity_lines()\n\\ No newline at end of file\ndiff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c89..456fd841 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -394,6 +394,7 @@ class Similar:\n \n     def _compute_sims(self) -> List[Tuple[int, Set[LinesChunkLimits_T]]]:\n         \"\"\"compute similarities in appended files\"\"\"\n+        print(f\"DEBUG: _compute_sims called with min_lines={self.min_lines}\")\n         no_duplicates: Dict[int, List[Set[LinesChunkLimits_T]]] = defaultdict(list)\n \n         for commonality in self._iter_sims():\n@@ -467,7 +468,7 @@ class Similar:\n         This the core of the algorithm.\n         The idea is to compute the hashes of a minimal number of successive lines of each lineset and then compare the hashes.\n         Every match of such comparison is stored in a dict that links the couple of starting indices in both linesets to\n-        the couple of corresponding starting and ending lines in both files.\n+        the couple of corresponding starting and ending number lines in both files.\n         Last regroups all successive couples in a bigger one. It allows to take into account common chunk of lines that have more\n         than the minimal number of successive lines required.\n         \"\"\"\n@@ -524,7 +525,7 @@ class Similar:\n                 lineset1, start_index_1, lineset2, start_index_2, nb_common_lines\n             )\n \n-            if eff_cmn_nb > self.min_lines:\n+            if self.min_lines > 0 and eff_cmn_nb >= self.min_lines:\n                 yield com\n \n     def _iter_sims(self) -> Generator[Commonality, None, None]:\n@@ -857,8 +858,11 @@ class SimilarChecker(BaseChecker, Similar, MapReduceMixin):\n         \"\"\"Reduces and recombines data into a format that we can report on\n \n         The partner function of get_map_data()\"\"\"\n+        print(f\"DEBUG: reduce_map_data called with self.min_lines={self.min_lines}\")\n         recombined = SimilarChecker(linter)\n+        print(f\"DEBUG: recombined.min_lines after init={recombined.min_lines}\")\n         recombined.min_lines = self.min_lines\n+        print(f\"DEBUG: recombined.min_lines after assignment={recombined.min_lines}\")\n         recombined.ignore_comments = self.ignore_comments\n         recombined.ignore_docstrings = self.ignore_docstrings\n         recombined.ignore_imports = self.ignore_imports\ndiff --git a/reproduce_issue.py b/reproduce_issue.py\nnew file mode 100644\nindex 00000000..f4d61bf5\n--- /dev/null\n+++ b/reproduce_issue.py\n@@ -0,0 +1,72 @@\n+#!/usr/bin/env python3\n+\n+\"\"\"\n+Script to reproduce the issue with min-similarity-lines=0\n+\"\"\"\n+\n+import tempfile\n+import os\n+import sys\n+from pylint.checkers import similar\n+from io import StringIO\n+from contextlib import redirect_stdout\n+\n+def test_min_similarity_lines_zero():\n+    \"\"\"Test that setting min-similarity-lines to 0 disables duplicate code checking\"\"\"\n+    # Create two identical files\n+    content = \"\"\"\n+def func1():\n+    x = 1\n+    y = 2\n+    return x + y\n+\n+def func2():\n+    x = 1\n+    y = 2\n+    return x + y\n+\"\"\"\n+    \n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f1:\n+        f1.write(content)\n+        file1 = f1.name\n+    \n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f2:\n+        f2.write(content)\n+        file2 = f2.name\n+    \n+    try:\n+        # Test with duplicates=0 using command line\n+        print(\"Testing with duplicates=0:\")\n+        output = StringIO()\n+        with redirect_stdout(output):\n+            try:\n+                similar.Run([\"--duplicates=0\", file1, file2])\n+            except SystemExit as e:\n+                if e.code != 0:\n+                    print(f\"ERROR: Command failed with exit code {e.code}\")\n+                    return False\n+        print(\"Output with duplicates=0:\")\n+        print(output.getvalue())\n+        \n+        # Test with duplicates=4 (default) to see if it detects duplicates\n+        print(\"\\nTesting with duplicates=4 (default):\")\n+        output = StringIO()\n+        with redirect_stdout(output):\n+            try:\n+                similar.Run([\"--duplicates=4\", file1, file2])\n+            except SystemExit as e:\n+                if e.code != 0:\n+                    print(f\"ERROR: Command failed with exit code {e.code}\")\n+                    return False\n+        print(\"Output with duplicates=4:\")\n+        print(output.getvalue())\n+        \n+        return True\n+            \n+    finally:\n+        # Clean up temporary files\n+        os.unlink(file1)\n+        os.unlink(file2)\n+\n+if __name__ == \"__main__\":\n+    test_min_similarity_lines_zero()\n\\ No newline at end of file\ndiff --git a/test_rcfile.ini b/test_rcfile.ini\nnew file mode 100644\nindex 00000000..19393d7b\n--- /dev/null\n+++ b/test_rcfile.ini\n@@ -0,0 +1,2 @@\n+[tool:pylint]\n+min-similarity-lines=0\n\\ No newline at end of file\ndiff --git a/test_rcfile.py b/test_rcfile.py\nnew file mode 100644\nindex 00000000..c7576c12\n--- /dev/null\n+++ b/test_rcfile.py\n@@ -0,0 +1,70 @@\n+#!/usr/bin/env python3\n+\n+\"\"\"\n+Script to reproduce the issue with min-similarity-lines=0 in rcfile\n+\"\"\"\n+\n+import tempfile\n+import os\n+from pylint.lint import PyLinter\n+from pylint.checkers import similar\n+from pylint.testutils import GenericTestReporter as Reporter\n+\n+def test_min_similarity_lines_zero_rcfile():\n+    \"\"\"Test that setting min-similarity-lines to 0 in rcfile disables duplicate code checking\"\"\"\n+    # Create two identical files\n+    content = \"\"\"\n+def func1():\n+    x = 1\n+    y = 2\n+    return x + y\n+\n+def func2():\n+    x = 1\n+    y = 2\n+    return x + y\n+\"\"\"\n+    \n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f1:\n+        f1.write(content)\n+        file1 = f1.name\n+    \n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f2:\n+        f2.write(content)\n+        file2 = f2.name\n+    \n+    try:\n+        # Create a linter with rcfile that sets min-similarity-lines=0\n+        linter = PyLinter(reporter=Reporter())\n+        linter.read_config_file(config_file=\"/testbed/test_rcfile.ini\")\n+        linter.load_config_file()\n+        \n+        # Register the similar checker\n+        checker = similar.SimilarChecker(linter)\n+        linter.register_checker(checker)\n+        \n+        # Check the files\n+        linter.check([file1, file2])\n+        \n+        # Check if any duplicate code messages were reported\n+        messages = linter.reporter.messages\n+        duplicate_messages = [msg for msg in messages if \"duplicate-code\" in str(msg)]\n+        \n+        print(f\"Number of duplicate-code messages: {len(duplicate_messages)}\")\n+        for msg in duplicate_messages:\n+            print(f\"Message: {msg}\")\n+            \n+        if len(duplicate_messages) > 0:\n+            print(\"ERROR: Setting min-similarity-lines=0 in rcfile should disable duplicate code checking\")\n+            return False\n+        else:\n+            print(\"SUCCESS: Setting min-similarity-lines=0 in rcfile disabled duplicate code checking\")\n+            return True\n+            \n+    finally:\n+        # Clean up temporary files\n+        os.unlink(file1)\n+        os.unlink(file2)\n+\n+if __name__ == \"__main__\":\n+    test_min_similarity_lines_zero_rcfile()\n\\ No newline at end of file\ndiff --git a/test_rcfile_detailed.py b/test_rcfile_detailed.py\nnew file mode 100644\nindex 00000000..2eb3f209\n--- /dev/null\n+++ b/test_rcfile_detailed.py\n@@ -0,0 +1,113 @@\n+#!/usr/bin/env python3\n+\n+\"\"\"\n+Script to reproduce the issue with min-similarity-lines=0 in rcfile\n+\"\"\"\n+\n+import tempfile\n+import os\n+from pylint.lint import PyLinter\n+from pylint.checkers import similar\n+from pylint.testutils import GenericTestReporter as Reporter\n+\n+def test_min_similarity_lines_zero_rcfile_detailed():\n+    \"\"\"Test that setting min-similarity-lines to 0 in rcfile disables duplicate code checking\"\"\"\n+    # Create two identical files with more content\n+    content = \"\"\"\n+def func1():\n+    # This is a comment\n+    x = 1\n+    y = 2\n+    z = 3\n+    a = 4\n+    b = 5\n+    c = 6\n+    return x + y + z + a + b + c\n+\n+def func2():\n+    # This is a comment\n+    x = 1\n+    y = 2\n+    z = 3\n+    a = 4\n+    b = 5\n+    c = 6\n+    return x + y + z + a + b + c\n+\n+def func3():\n+    # This is a comment\n+    x = 1\n+    y = 2\n+    z = 3\n+    a = 4\n+    b = 5\n+    c = 6\n+    return x + y + z + a + b + c\n+\"\"\"\n+    \n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f1:\n+        f1.write(content)\n+        file1 = f1.name\n+    \n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f2:\n+        f2.write(content)\n+        file2 = f2.name\n+    \n+    try:\n+        # Test with min-similarity-lines=0\n+        print(\"Testing with min-similarity-lines=0:\")\n+        linter = PyLinter(reporter=Reporter())\n+        checker = similar.SimilarChecker(linter)\n+        checker.set_option(\"min-similarity-lines\", 0)\n+        linter.register_checker(checker)\n+        \n+        # Check the files\n+        linter.check([file1, file2])\n+        \n+        # Check if any duplicate code messages were reported\n+        messages = linter.reporter.messages\n+        duplicate_messages = [msg for msg in messages if \"duplicate-code\" in str(msg)]\n+        \n+        print(f\"Number of duplicate-code messages: {len(duplicate_messages)}\")\n+        for msg in duplicate_messages:\n+            print(f\"Message: {msg}\")\n+            \n+        if len(duplicate_messages) > 0:\n+            print(\"ERROR: Setting min-similarity-lines=0 should disable duplicate code checking\")\n+            return False\n+        else:\n+            print(\"SUCCESS: Setting min-similarity-lines=0 disabled duplicate code checking\")\n+            \n+        # Test with min-similarity-lines=1\n+        print(\"\\nTesting with min-similarity-lines=1:\")\n+        linter = PyLinter(reporter=Reporter())\n+        checker = similar.SimilarChecker(linter)\n+        checker.set_option(\"min-similarity-lines\", 1)\n+        linter.register_checker(checker)\n+        \n+        # Check the files\n+        linter.check([file1, file2])\n+        \n+        # Check if any duplicate code messages were reported\n+        messages = linter.reporter.messages\n+        duplicate_messages = [msg for msg in messages if \"duplicate-code\" in str(msg)]\n+        \n+        print(f\"Number of duplicate-code messages: {len(duplicate_messages)}\")\n+        for msg in duplicate_messages:\n+            print(f\"Message: {msg}\")\n+            \n+        if len(duplicate_messages) > 0:\n+            print(\"With min-similarity-lines=1, duplicate code is detected (expected)\")\n+        else:\n+            print(\"ERROR: With min-similarity-lines=1, duplicate code should be detected\")\n+            return False\n+            \n+        return True\n+            \n+    finally:\n+        # Clean up temporary files\n+        os.unlink(file1)\n+        os.unlink(file2)\n+\n+if __name__ == \"__main__\":\n+    test_min_similarity_lines_zero_rcfile_detailed()\n\\ No newline at end of file\ndiff --git a/test_zero.py b/test_zero.py\nnew file mode 100644\nindex 00000000..fbd51994\n--- /dev/null\n+++ b/test_zero.py\n@@ -0,0 +1,81 @@\n+#!/usr/bin/env python3\n+\n+\"\"\"\n+Script to test that min-similarity-lines=0 disables duplicate code checking\n+\"\"\"\n+\n+import tempfile\n+import os\n+from pylint.lint import PyLinter\n+from pylint.checkers import similar\n+from pylint.testutils import GenericTestReporter as Reporter\n+\n+def test_min_similarity_lines_zero():\n+    \"\"\"Test that setting min-similarity-lines to 0 disables duplicate code checking\"\"\"\n+    # Create two identical files with more content\n+    content = \"\"\"\n+def func1():\n+    # This is a comment\n+    x = 1\n+    y = 2\n+    z = 3\n+    a = 4\n+    b = 5\n+    c = 6\n+    return x + y + z + a + b + c\n+\n+def func2():\n+    # This is a comment\n+    x = 1\n+    y = 2\n+    z = 3\n+    a = 4\n+    b = 5\n+    c = 6\n+    return x + y + z + a + b + c\n+\"\"\"\n+    \n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f1:\n+        f1.write(content)\n+        file1 = f1.name\n+    \n+    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f2:\n+        f2.write(content)\n+        file2 = f2.name\n+    \n+    try:\n+        # Test with min-similarity-lines=0\n+        print(\"Testing with min-similarity-lines=0:\")\n+        linter = PyLinter(reporter=Reporter())\n+        checker = similar.SimilarChecker(linter)\n+        linter.register_checker(checker)\n+        checker.set_option(\"min-similarity-lines\", 0)\n+        \n+        # Check the files\n+        linter.check([file1, file2])\n+        \n+        # Check if any duplicate code messages were reported\n+        print(f\"DEBUG: Reporter has {len(linter.reporter.messages)} messages\")\n+        for i, msg in enumerate(linter.reporter.messages):\n+            print(f\"DEBUG: Message {i}: {msg}\")\n+        messages = linter.reporter.messages\n+        duplicate_messages = [msg for msg in messages if \"Similar lines\" in str(msg)]\n+        \n+        print(f\"Number of duplicate-code messages: {len(duplicate_messages)}\")\n+        for msg in duplicate_messages:\n+            print(f\"Message: {msg}\")\n+            \n+        if len(duplicate_messages) > 0:\n+            print(\"ERROR: Setting min-similarity-lines=0 should disable duplicate code checking\")\n+            return False\n+        else:\n+            print(\"SUCCESS: Setting min-similarity-lines=0 disabled duplicate code checking\")\n+            return True\n+            \n+    finally:\n+        # Clean up temporary files\n+        os.unlink(file1)\n+        os.unlink(file2)\n+\n+if __name__ == \"__main__\":\n+    test_min_similarity_lines_zero()\n\\ No newline at end of file\n"
    },
    "pylint-dev__pylint-6386": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pylint-dev__pylint-6386",
        "model_patch": "diff --git a/pylint/lint/base_options.py b/pylint/lint/base_options.py\nindex c793cc85..56b5cbcd 100644\n--- a/pylint/lint/base_options.py\n+++ b/pylint/lint/base_options.py\n@@ -535,17 +535,7 @@ def _make_run_options(self: Run) -> Options:\n                 \"hide_from_config_file\": True,\n             },\n         ),\n-        (\n-            \"verbose\",\n-            {\n-                \"action\": _DoNothingAction,\n-                \"kwargs\": {},\n-                \"short\": \"v\",\n-                \"help\": \"In verbose mode, extra non-checker-related info \"\n-                \"will be displayed.\",\n-                \"hide_from_config_file\": True,\n-            },\n-        ),\n+        [['verbose', {'action': 'store_true', 'default': False, 'short': 'v', 'help': 'In verbose mode, extra non-checker-related info will be displayed.', 'hide_from_config_file': True}]]\n         (\n             \"enable-all-extensions\",\n             {\ndiff --git a/simple_test.py b/simple_test.py\nnew file mode 100644\nindex 00000000..3f394b4d\n--- /dev/null\n+++ b/simple_test.py\n@@ -0,0 +1,24 @@\n+import sys\n+import argparse\n+from pylint.config.callback_actions import _DoNothingAction\n+\n+# Create a simple argument parser to test the issue\n+parser = argparse.ArgumentParser()\n+\n+# Add the verbose option with _DoNothingAction (current implementation - without nargs)\n+parser.add_argument('-v', '--verbose', action=_DoNothingAction, help='Verbose mode')\n+\n+# Test parsing\n+try:\n+    args = parser.parse_args(['-v'])\n+    print(\"Success: Short form (-v) worked\")\n+    print(f\"Args: {args}\")\n+except SystemExit as e:\n+    print(f\"Error: Short form (-v) failed with exit code {e.code}\")\n+\n+try:\n+    args = parser.parse_args(['--verbose'])\n+    print(\"Success: Long form (--verbose) worked\")\n+    print(f\"Args: {args}\")\n+except SystemExit as e:\n+    print(f\"Error: Long form (--verbose) failed with exit code {e.code}\")\n\\ No newline at end of file\ndiff --git a/test_verbose.py b/test_verbose.py\nnew file mode 100644\nindex 00000000..a61789b5\n--- /dev/null\n+++ b/test_verbose.py\n@@ -0,0 +1,35 @@\n+import subprocess\n+import sys\n+import tempfile\n+import os\n+\n+# Create a temporary Python file for testing\n+with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n+    test_file = f.name\n+    f.write(\"print('Hello, world!')\\n\")\n+\n+try:\n+    # Test the long form (should work)\n+    print(\"Testing long form (--verbose):\")\n+    result = subprocess.run([sys.executable, \"-m\", \"pylint\", \"--verbose\", test_file], \n+                          capture_output=True, text=True)\n+    print(f\"Return code: {result.returncode}\")\n+    if result.stdout:\n+        print(f\"Stdout: {result.stdout}\")\n+    if result.stderr:\n+        print(f\"Stderr: {result.stderr}\")\n+    \n+    print(\"\\n\" + \"=\"*50 + \"\\n\")\n+    \n+    # Test the short form (should fail with current code)\n+    print(\"Testing short form (-v):\")\n+    result = subprocess.run([sys.executable, \"-m\", \"pylint\", \"-v\", test_file], \n+                          capture_output=True, text=True)\n+    print(f\"Return code: {result.returncode}\")\n+    if result.stdout:\n+        print(f\"Stdout: {result.stdout}\")\n+    if result.stderr:\n+        print(f\"Stderr: {result.stderr}\")\n+finally:\n+    # Clean up the temporary file\n+    os.unlink(test_file)\n\\ No newline at end of file\n"
    },
    "pylint-dev__pylint-6528": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pylint-dev__pylint-6528",
        "model_patch": "diff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex 53345a6b..b8bcaaf1 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -564,8 +564,9 @@ class PyLinter(\n             if not msg.may_be_emitted():\n                 self._msgs_state[msg.msgid] = False\n \n-    @staticmethod\n-    def _discover_files(files_or_modules: Sequence[str]) -> Iterator[str]:\n+    def _discover_files(\n+        self, files_or_modules: Sequence[str]\n+    ) -> Iterator[str]:\n         \"\"\"Discover python modules and packages in sub-directory.\n \n         Returns iterator of paths to discovered modules and packages.\n@@ -576,6 +577,15 @@ class PyLinter(\n             ):\n                 skip_subtrees: list[str] = []\n                 for root, _, files in os.walk(something):\n+                    # Check if the current directory should be ignored\n+                    basename = os.path.basename(root)\n+                    if (\n+                        basename in self.config.ignore\n+                        or any(pattern.match(basename) for pattern in self.config.ignore_patterns)\n+                        or any(pattern.match(root) for pattern in self.config.ignore_paths)\n+                    ):\n+                        continue\n+                    \n                     if any(root.startswith(s) for s in skip_subtrees):\n                         # Skip subtree of already discovered package.\n                         continue\n@@ -587,6 +597,11 @@ class PyLinter(\n                             os.path.join(root, file)\n                             for file in files\n                             if file.endswith(\".py\")\n+                            and not (\n+                                file in self.config.ignore\n+                                or any(pattern.match(file) for pattern in self.config.ignore_patterns)\n+                                or any(pattern.match(os.path.join(root, file)) for pattern in self.config.ignore_paths)\n+                            )\n                         )\n             else:\n                 yield something\n"
    },
    "pylint-dev__pylint-6903": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pylint-dev__pylint-6903",
        "model_patch": "diff --git a/pylint/lint/run.py b/pylint/lint/run.py\nindex a7e5d557..297f84e5 100644\n--- a/pylint/lint/run.py\n+++ b/pylint/lint/run.py\n@@ -58,6 +58,10 @@ def _query_cpu() -> int | None:\n             cpu_shares = int(file.read().rstrip())\n         # For AWS, gives correct value * 1024.\n         avail_cpu = int(cpu_shares / 1024)\n+    \n+    # Ensure we return at least 1 CPU if we have a value\n+    if avail_cpu is not None:\n+        return max(1, avail_cpu)\n     return avail_cpu\n \n \n"
    },
    "pylint-dev__pylint-7080": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pylint-dev__pylint-7080",
        "model_patch": "diff --git a/pylint/config/config_file_parser.py b/pylint/config/config_file_parser.py\nindex 3d769495..f69407f0 100644\n--- a/pylint/config/config_file_parser.py\n+++ b/pylint/config/config_file_parser.py\n@@ -85,16 +85,19 @@ class _ConfigurationFileParser:\n \n         config_content: dict[str, str] = {}\n         options: list[str] = []\n-        for opt, values in sections_values.items():\n-            if isinstance(values, dict):\n-                for config, value in values.items():\n+        for section_name, section_values in sections_values.items():\n+            if isinstance(section_values, dict):\n+                # This is a section (like [tool.pylint.MASTER] or [tool.pylint.main])\n+                # Extract all options from within this section\n+                for config, value in section_values.items():\n                     value = _parse_rich_type_value(value)\n                     config_content[config] = value\n                     options += [f\"--{config}\", value]\n             else:\n-                values = _parse_rich_type_value(values)\n-                config_content[opt] = values\n-                options += [f\"--{opt}\", values]\n+                # This is a direct option (not in a section)\n+                value = _parse_rich_type_value(section_values)\n+                config_content[section_name] = value\n+                options += [f\"--{section_name}\", value]\n         return config_content, options\n \n     def parse_config_file(\ndiff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex e2bbf061..29694b4c 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -614,6 +614,12 @@ class PyLinter(\n                             os.path.join(root, file)\n                             for file in files\n                             if file.endswith(\".py\")\n+                            and not _is_ignored_file(\n+                                os.path.join(root, file),\n+                                self.config.ignore,\n+                                self.config.ignore_patterns,\n+                                self.config.ignore_paths,\n+                            )\n                         )\n             else:\n                 yield something\n"
    },
    "pylint-dev__pylint-7277": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pylint-dev__pylint-7277",
        "model_patch": "diff --git a/pylint/__init__.py b/pylint/__init__.py\nindex 9f3dd74e..af1b7393 100644\n--- a/pylint/__init__.py\n+++ b/pylint/__init__.py\n@@ -86,7 +86,7 @@ def modify_sys_path() -> None:\n     stdlib or pylint's own modules.\n     CPython issue: https://bugs.python.org/issue33053\n \n-    - Remove the first entry. This will always be either \"\" or the working directory\n+    - Remove the first entry only if it is \"\", \".\" or the current working directory\n     - Remove the working directory from the second and third entries\n       if PYTHONPATH includes a \":\" at the beginning or the end.\n       https://github.com/PyCQA/pylint/issues/3636\n@@ -96,9 +96,12 @@ def modify_sys_path() -> None:\n       if pylint is installed in an editable configuration (as the last item).\n       https://github.com/PyCQA/pylint/issues/4161\n     \"\"\"\n-    sys.path.pop(0)\n-    env_pythonpath = os.environ.get(\"PYTHONPATH\", \"\")\n+    # Only remove the first entry if it is \"\", \".\" or the current working directory\n     cwd = os.getcwd()\n+    if sys.path and sys.path[0] in (\"\", \".\", cwd):\n+        sys.path.pop(0)\n+    \n+    env_pythonpath = os.environ.get(\"PYTHONPATH\", \"\")\n     if env_pythonpath.startswith(\":\") and env_pythonpath not in (f\":{cwd}\", \":.\"):\n         sys.path.pop(0)\n     elif env_pythonpath.endswith(\":\") and env_pythonpath not in (f\"{cwd}:\", \".:\"):\n"
    },
    "pylint-dev__pylint-8898": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pylint-dev__pylint-8898",
        "model_patch": "diff --git a/pylint/config/argument.py b/pylint/config/argument.py\nindex 30a5fd175..0495d30c5 100644\n--- a/pylint/config/argument.py\n+++ b/pylint/config/argument.py\n@@ -113,8 +113,33 @@ def _regex_transformer(value: str) -> Pattern[str]:\n \n def _regexp_csv_transfomer(value: str) -> Sequence[Pattern[str]]:\n     \"\"\"Transforms a comma separated list of regular expressions.\"\"\"\n+    # Handle escaped commas in regexes\n+    # Split on commas that are not escaped with a backslash\n+    parts = []\n+    current_part = \"\"\n+    i = 0\n+    while i < len(value):\n+        if value[i] == '\\\\' and i + 1 < len(value) and value[i + 1] == ',':\n+            # Escaped comma, add the comma without the backslash\n+            current_part += ','\n+            i += 2\n+        elif value[i] == ',':\n+            # Unescaped comma, end of current part\n+            parts.append(current_part.strip())\n+            current_part = \"\"\n+            i += 1\n+        else:\n+            current_part += value[i]\n+            i += 1\n+    # Add the last part\n+    if current_part:\n+        parts.append(current_part.strip())\n+    \n+    # Filter out empty parts\n+    parts = [part for part in parts if part]\n+    \n     patterns: list[Pattern[str]] = []\n-    for pattern in _csv_transformer(value):\n+    for pattern in parts:\n         patterns.append(_regex_transformer(pattern))\n     return patterns\n \ndiff --git a/tests/config/test_config.py b/tests/config/test_config.py\nindex 83c8b072e..a67bbb28e 100644\n--- a/tests/config/test_config.py\n+++ b/tests/config/test_config.py\n@@ -137,7 +137,7 @@ def test_csv_regex_error(capsys: CaptureFixture) -> None:\n     \"\"\"\n     with pytest.raises(SystemExit):\n         Run(\n-            [str(EMPTY_MODULE), r\"--bad-names-rgx=(foo{1,3})\"],\n+            [str(EMPTY_MODULE), r\"--bad-names-rgxs=(foo{1,3})\"],\n             exit=False,\n         )\n     output = capsys.readouterr()\n@@ -147,6 +147,18 @@ def test_csv_regex_error(capsys: CaptureFixture) -> None:\n     )\n \n \n+def test_csv_regex_with_escaped_comma(capsys: CaptureFixture) -> None:\n+    \"\"\"Check that we correctly handle regexes with escaped commas.\"\"\"\n+    # This should not raise SystemExit because the regex is valid\n+    Run(\n+        [str(EMPTY_MODULE), r\"--bad-names-rgxs=(foo{1\\,3})\"],\n+        exit=False,\n+    )\n+    output = capsys.readouterr()\n+    # Should not have the regex error\n+    assert \"Error in provided regular expression\" not in output.err\n+\n+\n def test_short_verbose(capsys: CaptureFixture) -> None:\n     \"\"\"Check that we correctly handle the -v flag.\"\"\"\n     Run([str(EMPTY_MODULE), \"-v\"], exit=False)\n"
    },
    "pytest-dev__pytest-10051": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-10051",
        "model_patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\nindex a4f4214b1..6709bf8b4 100644\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -441,6 +441,10 @@ class LogCaptureFixture:\n     def clear(self) -> None:\n         \"\"\"Reset the list of log records and the captured log text.\"\"\"\n         self.handler.reset()\n+        # Update the records in the stash for all phases\n+        records_dict = self._item.stash.get(caplog_records_key, {})\n+        for when in records_dict:\n+            records_dict[when] = self.handler.records\n \n     def set_level(self, level: Union[int, str], logger: Optional[str] = None) -> None:\n         \"\"\"Set the level of a logger for the duration of a test.\n"
    },
    "pytest-dev__pytest-10081": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-10081",
        "model_patch": "diff --git a/src/_pytest/unittest.py b/src/_pytest/unittest.py\nindex 851e4943b..fc8716454 100644\n--- a/src/_pytest/unittest.py\n+++ b/src/_pytest/unittest.py\n@@ -316,7 +316,7 @@ class TestCaseFunction(Function):\n             # Arguably we could always postpone tearDown(), but this changes the moment where the\n             # TestCase instance interacts with the results object, so better to only do it\n             # when absolutely needed.\n-            if self.config.getoption(\"usepdb\") and not _is_skipped(self.obj):\n+            if self.config.getoption(\"usepdb\") and not _is_skipped(self.obj) and not _is_skipped(self.parent.obj):\n                 self._explicit_tearDown = self._testcase.tearDown\n                 setattr(self._testcase, \"tearDown\", lambda *args: None)\n \n"
    },
    "pytest-dev__pytest-10356": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-10356",
        "model_patch": "diff --git a/src/_pytest/mark/structures.py b/src/_pytest/mark/structures.py\nindex 800a25c92..fae5fef78 100644\n--- a/src/_pytest/mark/structures.py\n+++ b/src/_pytest/mark/structures.py\n@@ -357,10 +357,26 @@ class MarkDecorator:\n \n def get_unpacked_marks(obj: object) -> Iterable[Mark]:\n     \"\"\"Obtain the unpacked marks that are stored on an object.\"\"\"\n-    mark_list = getattr(obj, \"pytestmark\", [])\n-    if not isinstance(mark_list, list):\n-        mark_list = [mark_list]\n-    return normalize_mark_list(mark_list)\n+    # If obj is a class, consider marks from all classes in the MRO\n+    if isinstance(obj, type):\n+        marks = []\n+        seen_mark_names = set()\n+        for cls in obj.__mro__:\n+            mark_list = getattr(cls, \"pytestmark\", [])\n+            if not isinstance(mark_list, list):\n+                mark_list = [mark_list]\n+            # Add marks, but avoid duplicates by name (MRO order)\n+            for mark in mark_list:\n+                if mark.name not in seen_mark_names:\n+                    marks.append(mark)\n+                    seen_mark_names.add(mark.name)\n+        return normalize_mark_list(marks)\n+    else:\n+        # For non-class objects, use the original behavior\n+        mark_list = getattr(obj, \"pytestmark\", [])\n+        if not isinstance(mark_list, list):\n+            mark_list = [mark_list]\n+        return normalize_mark_list(mark_list)\n \n \n def normalize_mark_list(\ndiff --git a/testing/test_multiple_inheritance_marks.py b/testing/test_multiple_inheritance_marks.py\nnew file mode 100644\nindex 000000000..e8a84e084\n--- /dev/null\n+++ b/testing/test_multiple_inheritance_marks.py\n@@ -0,0 +1,55 @@\n+import pytest\n+\n+def test_multiple_inheritance_marks() -> None:\n+    \"\"\"Test that marks from multiple base classes are correctly merged.\"\"\"\n+    # Create a simple test to check our fix\n+    import sys\n+    from _pytest.mark.structures import get_unpacked_marks\n+    \n+    # Define classes with marks\n+    @pytest.mark.foo\n+    class Foo(object):\n+        pass\n+\n+    @pytest.mark.bar\n+    class Bar(object):\n+        pass\n+\n+    class TestDings(Foo, Bar):\n+        def test_dings(self):\n+            pass\n+    \n+    # Check that both marks are present\n+    marks = list(get_unpacked_marks(TestDings))\n+    mark_names = [mark.name for mark in marks]\n+    \n+    assert \"foo\" in mark_names\n+    assert \"bar\" in mark_names\n+    assert len(marks) == 2\n+\n+def test_multiple_inheritance_marks_with_same_name() -> None:\n+    \"\"\"Test that marks with the same name from different base classes are handled correctly.\"\"\"\n+    # Create a simple test to check our fix\n+    import sys\n+    from _pytest.mark.structures import get_unpacked_marks\n+    \n+    # Define classes with marks\n+    @pytest.mark.skip(param=\"base1\")\n+    class Base1(object):\n+        pass\n+\n+    @pytest.mark.skip(param=\"base2\")\n+    class Base2(object):\n+        pass\n+\n+    class TestDings(Base1, Base2):\n+        def test_dings(self):\n+            pass\n+    \n+    # Check that only one marker is present (from the first base class in MRO)\n+    marks = list(get_unpacked_marks(TestDings))\n+    mark_names = [mark.name for mark in marks]\n+    \n+    assert \"skip\" in mark_names\n+    assert len(marks) == 1\n+    assert marks[0].kwargs == {\"param\": \"base1\"}\n\\ No newline at end of file\n"
    },
    "pytest-dev__pytest-5262": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-5262",
        "model_patch": "diff --git a/src/_pytest/capture.py b/src/_pytest/capture.py\nindex 25eab7fd..6759614e 100644\n--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -447,6 +447,15 @@ class EncodedFile(object):\n         \"\"\"Ensure that file.name is a string.\"\"\"\n         return repr(self.buffer)\n \n+    @property\n+    def mode(self):\n+        \"\"\"Return the mode of the file, without 'b' even if the underlying buffer is binary.\"\"\"\n+        buffer_mode = getattr(self.buffer, \"mode\", None)\n+        if buffer_mode and \"b\" in buffer_mode:\n+            # Remove 'b' from mode since EncodedFile handles text, not binary data\n+            return buffer_mode.replace(\"b\", \"\")\n+        return buffer_mode\n+\n     def __getattr__(self, name):\n         return getattr(object.__getattribute__(self, \"buffer\"), name)\n \n"
    },
    "pytest-dev__pytest-5631": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-5631",
        "model_patch": "diff --git a/src/_pytest/compat.py b/src/_pytest/compat.py\nindex d238061b4..1c332d1a0 100644\n--- a/src/_pytest/compat.py\n+++ b/src/_pytest/compat.py\n@@ -67,9 +67,18 @@ def num_mock_patch_args(function):\n     mock_modules = [sys.modules.get(\"mock\"), sys.modules.get(\"unittest.mock\")]\n     if any(mock_modules):\n         sentinels = [m.DEFAULT for m in mock_modules if m is not None]\n-        return len(\n-            [p for p in patchings if not p.attribute_name and p.new in sentinels]\n-        )\n+        count = 0\n+        for p in patchings:\n+            if not p.attribute_name:\n+                try:\n+                    # Check if p.new is in sentinels, but handle the case where\n+                    # p.new is an array-like object that would cause a ValueError\n+                    if p.new in sentinels:\n+                        count += 1\n+                except ValueError:\n+                    # If p.new is an array-like object, it's not a sentinel\n+                    pass\n+        return count\n     return len(patchings)\n \n \n"
    },
    "pytest-dev__pytest-5787": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-5787",
        "model_patch": "diff --git a/src/_pytest/reports.py b/src/_pytest/reports.py\nindex 4682d5b6e..649391836 100644\n--- a/src/_pytest/reports.py\n+++ b/src/_pytest/reports.py\n@@ -3,6 +3,7 @@ from typing import Optional\n \n import py\n \n+from _pytest._code.code import ExceptionChainRepr\n from _pytest._code.code import ExceptionInfo\n from _pytest._code.code import ReprEntry\n from _pytest._code.code import ReprEntryNative\n@@ -184,9 +185,37 @@ class BaseReport:\n                 \"sections\": rep.longrepr.sections,\n             }\n \n+        def disassembled_chainrep(rep):\n+            chain = []\n+            for reprtraceback, reprcrash, descr in rep.longrepr.chain:\n+                reprtraceback_data = reprtraceback.__dict__.copy()\n+                reprcrash_data = reprcrash.__dict__.copy() if reprcrash else None\n+\n+                new_entries = []\n+                for entry in reprtraceback_data[\"reprentries\"]:\n+                    entry_data = {\n+                        \"type\": type(entry).__name__,\n+                        \"data\": entry.__dict__.copy(),\n+                    }\n+                    for key, value in entry_data[\"data\"].items():\n+                        if hasattr(value, \"__dict__\"):\n+                            entry_data[\"data\"][key] = value.__dict__.copy()\n+                    new_entries.append(entry_data)\n+\n+                reprtraceback_data[\"reprentries\"] = new_entries\n+\n+                chain.append((reprtraceback_data, reprcrash_data, descr))\n+\n+            return {\n+                \"chain\": chain,\n+                \"sections\": rep.longrepr.sections,\n+            }\n+\n         d = self.__dict__.copy()\n         if hasattr(self.longrepr, \"toterminal\"):\n-            if hasattr(self.longrepr, \"reprtraceback\") and hasattr(\n+            if hasattr(self.longrepr, \"chain\"):\n+                d[\"longrepr\"] = disassembled_chainrep(self)\n+            elif hasattr(self.longrepr, \"reprtraceback\") and hasattr(\n                 self.longrepr, \"reprcrash\"\n             ):\n                 d[\"longrepr\"] = disassembled_report(self)\n@@ -255,6 +284,47 @@ class BaseReport:\n                     reprcrash=ReprFileLocation(**reprcrash),\n                 )\n \n+                for section in reportdict[\"longrepr\"][\"sections\"]:\n+                    exception_info.addsection(*section)\n+                reportdict[\"longrepr\"] = exception_info\n+            elif \"chain\" in reportdict[\"longrepr\"]:\n+                chain = []\n+                for reprtraceback_data, reprcrash_data, descr in reportdict[\"longrepr\"][\"chain\"]:\n+                    unserialized_entries = []\n+                    for entry_data in reprtraceback_data[\"reprentries\"]:\n+                        data = entry_data[\"data\"]\n+                        entry_type = entry_data[\"type\"]\n+                        if entry_type == \"ReprEntry\":\n+                            reprfuncargs = None\n+                            reprfileloc = None\n+                            reprlocals = None\n+                            if data[\"reprfuncargs\"]:\n+                                reprfuncargs = ReprFuncArgs(**data[\"reprfuncargs\"])\n+                            if data[\"reprfileloc\"]:\n+                                reprfileloc = ReprFileLocation(**data[\"reprfileloc\"])\n+                            if data[\"reprlocals\"]:\n+                                reprlocals = ReprLocals(data[\"reprlocals\"][\"lines\"])\n+\n+                            reprentry = ReprEntry(\n+                                lines=data[\"lines\"],\n+                                reprfuncargs=reprfuncargs,\n+                                reprlocals=reprlocals,\n+                                filelocrepr=reprfileloc,\n+                                style=data[\"style\"],\n+                            )\n+                        elif entry_type == \"ReprEntryNative\":\n+                            reprentry = ReprEntryNative(data[\"lines\"])\n+                        else:\n+                            _report_unserialization_failure(entry_type, cls, reportdict)\n+                        unserialized_entries.append(reprentry)\n+                    reprtraceback_data[\"reprentries\"] = unserialized_entries\n+\n+                    reprtraceback = ReprTraceback(**reprtraceback_data)\n+                    reprcrash = ReprFileLocation(**reprcrash_data) if reprcrash_data else None\n+                    chain.append((reprtraceback, reprcrash, descr))\n+\n+                exception_info = ExceptionChainRepr(chain)\n+\n                 for section in reportdict[\"longrepr\"][\"sections\"]:\n                     exception_info.addsection(*section)\n                 reportdict[\"longrepr\"] = exception_info\n"
    },
    "pytest-dev__pytest-5809": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-5809",
        "model_patch": "diff --git a/src/_pytest/pastebin.py b/src/_pytest/pastebin.py\nindex 41576a615..79b0d9d40 100644\n--- a/src/_pytest/pastebin.py\n+++ b/src/_pytest/pastebin.py\n@@ -79,7 +79,7 @@ def create_new_paste(contents):\n \n     params = {\n         \"code\": contents,\n-        \"lexer\": \"python3\" if sys.version_info[0] >= 3 else \"python\",\n+        \"lexer\": \"text\",\n         \"expiry\": \"1week\",\n     }\n     url = \"https://bpaste.net\"\ndiff --git a/testing/test_pastebin.py b/testing/test_pastebin.py\nindex bac8f9802..aac0b651e 100644\n--- a/testing/test_pastebin.py\n+++ b/testing/test_pastebin.py\n@@ -126,8 +126,7 @@ class TestPaste(object):\n         assert len(mocked_urlopen) == 1\n         url, data = mocked_urlopen[0]\n         assert type(data) is bytes\n-        lexer = \"python3\" if sys.version_info[0] >= 3 else \"python\"\n         assert url == \"https://bpaste.net\"\n-        assert \"lexer=%s\" % lexer in data.decode()\n+        assert \"lexer=text\" in data.decode()\n         assert \"code=full-paste-contents\" in data.decode()\n         assert \"expiry=1week\" in data.decode()\n"
    },
    "pytest-dev__pytest-5840": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-5840",
        "model_patch": "diff --git a/src/_pytest/config/__init__.py b/src/_pytest/config/__init__.py\nindex 3a0eca546..f26eed0cb 100644\n--- a/src/_pytest/config/__init__.py\n+++ b/src/_pytest/config/__init__.py\n@@ -435,14 +435,15 @@ class PytestPluginManager(PluginManager):\n         # Use realpath to avoid loading the same conftest twice\n         # with build systems that create build directories containing\n         # symlinks to actual files.\n-        conftestpath = unique_path(conftestpath)\n+        normalized_path = unique_path(conftestpath)\n         try:\n-            return self._conftestpath2mod[conftestpath]\n+            return self._conftestpath2mod[normalized_path]\n         except KeyError:\n-            pkgpath = conftestpath.pypkgpath()\n+            pkgpath = normalized_path.pypkgpath()\n             if pkgpath is None:\n-                _ensure_removed_sysmodule(conftestpath.purebasename)\n+                _ensure_removed_sysmodule(normalized_path.purebasename)\n             try:\n+                # Use the original path for importing to preserve case\n                 mod = conftestpath.pyimport()\n                 if (\n                     hasattr(mod, \"pytest_plugins\")\n@@ -454,7 +455,7 @@ class PytestPluginManager(PluginManager):\n                 raise ConftestImportFailure(conftestpath, sys.exc_info())\n \n             self._conftest_plugins.add(mod)\n-            self._conftestpath2mod[conftestpath] = mod\n+            self._conftestpath2mod[normalized_path] = mod\n             dirpath = conftestpath.dirpath()\n             if dirpath in self._dirpath2confmods:\n                 for path, mods in self._dirpath2confmods.items():\n"
    },
    "pytest-dev__pytest-6197": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-6197",
        "model_patch": "diff --git a/src/_pytest/main.py b/src/_pytest/main.py\nindex 3c205027d..eea8196c3 100644\n--- a/src/_pytest/main.py\n+++ b/src/_pytest/main.py\n@@ -564,13 +564,9 @@ class Session(nodes.FSCollector):\n             # Module itself, so just use that. If this special case isn't taken, then all\n             # the files in the package will be yielded.\n             if argpath.basename == \"__init__.py\":\n-                try:\n-                    yield next(m[0].collect())\n-                except StopIteration:\n-                    # The package collects nothing with only an __init__.py\n-                    # file in it, which gets ignored by the default\n-                    # \"python_files\" option.\n-                    pass\n+                collected = m[0].collect()\n+                if collected:\n+                    yield from collected\n                 return\n             yield from m\n \ndiff --git a/src/_pytest/python.py b/src/_pytest/python.py\nindex 306e5f217..6810bed6d 100644\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -176,9 +176,20 @@ def pytest_pyfunc_call(pyfuncitem):\n def pytest_collect_file(path, parent):\n     ext = path.ext\n     if ext == \".py\":\n-        if not parent.session.isinitpath(path):\n-            if not path_matches_patterns(\n-                path, parent.config.getini(\"python_files\") + [\"__init__.py\"]\n+        # If the path is explicitly specified by the user, collect it\n+        if parent.session.isinitpath(path):\n+            # Collect explicitly specified paths\n+            pass\n+        else:\n+            # For __init__.py files, only collect them if they match the python_files pattern\n+            if path.basename == \"__init__.py\":\n+                if not path_matches_patterns(\n+                    path, parent.config.getini(\"python_files\")\n+                ):\n+                    return\n+            # For other .py files, collect them if they match the python_files pattern\n+            elif not path_matches_patterns(\n+                path, parent.config.getini(\"python_files\")\n             ):\n                 return\n         ihook = parent.session.gethookproxy(path)\n@@ -192,6 +203,9 @@ def path_matches_patterns(path, patterns):\n \n def pytest_pycollect_makemodule(path, parent):\n     if path.basename == \"__init__.py\":\n+        # If the path is explicitly specified by the user, treat it as a Module\n+        if parent.session.isinitpath(path):\n+            return Module(path, parent)\n         return Package(path, parent)\n     return Module(path, parent)\n \n"
    },
    "pytest-dev__pytest-6202": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-6202",
        "model_patch": "diff --git a/src/_pytest/python.py b/src/_pytest/python.py\nindex b8b365ad3..5f2af31e2 100644\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -286,7 +286,7 @@ class PyobjMixin(PyobjContext):\n             parts.append(name)\n         parts.reverse()\n         s = \".\".join(parts)\n-        return s.replace(\".[\", \"[\")\n+        return s\n \n     def reportinfo(self):\n         # XXX caching?\n"
    },
    "pytest-dev__pytest-7205": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-7205",
        "model_patch": "diff --git a/src/_pytest/setuponly.py b/src/_pytest/setuponly.py\nindex c9cc589ff..9fc218a3e 100644\n--- a/src/_pytest/setuponly.py\n+++ b/src/_pytest/setuponly.py\n@@ -1,4 +1,5 @@\n import pytest\n+from _pytest._io.saferepr import saferepr\n \n \n def pytest_addoption(parser):\n@@ -66,7 +67,7 @@ def _show_fixture_action(fixturedef, msg):\n             tw.write(\" (fixtures used: {})\".format(\", \".join(deps)))\n \n     if hasattr(fixturedef, \"cached_param\"):\n-        tw.write(\"[{}]\".format(fixturedef.cached_param))\n+        tw.write(\"[{}]\".format(saferepr(fixturedef.cached_param)))\n \n     tw.flush()\n \n"
    },
    "pytest-dev__pytest-7236": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-7236",
        "model_patch": "diff --git a/src/_pytest/unittest.py b/src/_pytest/unittest.py\nindex 773f545af..b07c7a6cb 100644\n--- a/src/_pytest/unittest.py\n+++ b/src/_pytest/unittest.py\n@@ -220,7 +220,15 @@ class TestCaseFunction(Function):\n             # arguably we could always postpone tearDown(), but this changes the moment where the\n             # TestCase instance interacts with the results object, so better to only do it\n             # when absolutely needed\n-            if self.config.getoption(\"usepdb\"):\n+            # However, we should not do this for skipped tests, as tearDown should not be called for them\n+            # Let's check if the test is skipped\n+            # Check if the test method itself is skipped\n+            test_method = getattr(self._testcase, self.name)\n+            method_is_skipped = getattr(test_method, \"__unittest_skip__\", False)\n+            # Check if the class is skipped\n+            class_is_skipped = getattr(self._testcase, \"__unittest_skip__\", False)\n+            is_skipped = method_is_skipped or class_is_skipped\n+            if self.config.getoption(\"usepdb\") and not is_skipped:\n                 self._explicit_tearDown = self._testcase.tearDown\n                 setattr(self._testcase, \"tearDown\", lambda *args: None)\n \n"
    },
    "pytest-dev__pytest-7324": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-7324",
        "model_patch": "diff --git a/src/_pytest/mark/expression.py b/src/_pytest/mark/expression.py\nindex 04c73411a..9abdecdc7 100644\n--- a/src/_pytest/mark/expression.py\n+++ b/src/_pytest/mark/expression.py\n@@ -161,7 +161,11 @@ def not_expr(s: Scanner) -> ast.expr:\n         return ret\n     ident = s.accept(TokenType.IDENT)\n     if ident:\n-        return ast.Name(ident.value, ast.Load())\n+        # Mangle Python keywords to avoid conflicts in Python 3.8+\n+        value = ident.value\n+        if value in (\"True\", \"False\", \"None\"):\n+            value = \"$\" + value\n+        return ast.Name(value, ast.Load())\n     s.reject((TokenType.NOT, TokenType.LPAREN, TokenType.IDENT))\n \n \n@@ -172,6 +176,9 @@ class MatcherAdapter(Mapping[str, bool]):\n         self.matcher = matcher\n \n     def __getitem__(self, key: str) -> bool:\n+        # Unmangle Python keywords\n+        if key.startswith(\"$\") and key[1:] in (\"True\", \"False\", \"None\"):\n+            key = key[1:]\n         return self.matcher(key)\n \n     def __iter__(self) -> Iterator[str]:\n"
    },
    "pytest-dev__pytest-7432": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-7432",
        "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 7bd975e5a..691347be8 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -262,6 +262,20 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n     rep = outcome.get_result()\n     xfailed = item._store.get(xfailed_key, None)\n+    # Handle skip location reporting first, regardless of --runxfail\n+    if (\n+        item._store.get(skipped_by_mark_key, True)\n+        and rep.skipped\n+        and type(rep.longrepr) is tuple\n+    ):\n+        # skipped by mark.skipif; change the location of the failure\n+        # to point to the item definition, otherwise it will display\n+        # the location of where the skip exception was raised within pytest\n+        _, _, reason = rep.longrepr\n+        filename, line = item.reportinfo()[:2]\n+        assert line is not None\n+        rep.longrepr = str(filename), line + 1, reason\n+\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]\n@@ -270,13 +284,11 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n         else:\n             rep.longrepr = \"Unexpected success\"\n         rep.outcome = \"failed\"\n-    elif item.config.option.runxfail:\n-        pass  # don't interfere\n     elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n         assert call.excinfo.value.msg is not None\n         rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n         rep.outcome = \"skipped\"\n-    elif not rep.skipped and xfailed:\n+    elif not rep.skipped and xfailed and not item.config.option.runxfail:\n         if call.excinfo:\n             raises = xfailed.raises\n             if raises is not None and not isinstance(call.excinfo.value, raises):\n@@ -291,18 +303,6 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n-        item._store.get(skipped_by_mark_key, True)\n-        and rep.skipped\n-        and type(rep.longrepr) is tuple\n-    ):\n-        # skipped by mark.skipif; change the location of the failure\n-        # to point to the item definition, otherwise it will display\n-        # the location of where the skip exception was raised within pytest\n-        _, _, reason = rep.longrepr\n-        filename, line = item.reportinfo()[:2]\n-        assert line is not None\n-        rep.longrepr = str(filename), line + 1, reason\n \n \n def pytest_report_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n"
    },
    "pytest-dev__pytest-7490": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-7490",
        "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..ff4dec977 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -276,21 +276,32 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n         assert call.excinfo.value.msg is not None\n         rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n         rep.outcome = \"skipped\"\n-    elif not rep.skipped and xfailed:\n-        if call.excinfo:\n-            raises = xfailed.raises\n-            if raises is not None and not isinstance(call.excinfo.value, raises):\n-                rep.outcome = \"failed\"\n-            else:\n-                rep.outcome = \"skipped\"\n-                rep.wasxfail = xfailed.reason\n-        elif call.when == \"call\":\n-            if xfailed.strict:\n-                rep.outcome = \"failed\"\n-                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n-            else:\n-                rep.outcome = \"passed\"\n-                rep.wasxfail = xfailed.reason\n+    else:\n+        # Re-evaluate xfail marks if we have a failure and no xfail was previously detected.\n+        # This handles the case where xfail marks are added dynamically during test execution.\n+        # Only do this during the 'call' phase to avoid interfering with setup/teardown errors.\n+        if xfailed is None and call.excinfo and not rep.skipped and call.when == \"call\":\n+            try:\n+                xfailed = evaluate_xfail_marks(item)\n+            except Exception:\n+                # If evaluating xfail marks fails, we ignore it to avoid masking the original error.\n+                # This maintains the same behavior as the original code.\n+                pass\n+        if not rep.skipped and xfailed:\n+            if call.excinfo:\n+                raises = xfailed.raises\n+                if raises is not None and not isinstance(call.excinfo.value, raises):\n+                    rep.outcome = \"failed\"\n+                else:\n+                    rep.outcome = \"skipped\"\n+                    rep.wasxfail = xfailed.reason\n+            elif call.when == \"call\":\n+                if xfailed.strict:\n+                    rep.outcome = \"failed\"\n+                    rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n+                else:\n+                    rep.outcome = \"passed\"\n+                    rep.wasxfail = xfailed.reason\n \n     if (\n         item._store.get(skipped_by_mark_key, True)\n"
    },
    "pytest-dev__pytest-7521": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-7521",
        "model_patch": "diff --git a/src/_pytest/capture.py b/src/_pytest/capture.py\nindex 3f9c60fb9..01d2706f8 100644\n--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -388,6 +388,7 @@ class FDCaptureBinary:\n                 TemporaryFile(buffering=0),  # type: ignore[arg-type]\n                 encoding=\"utf-8\",\n                 errors=\"replace\",\n+                newline=\"\",  # Don't translate newlines\n                 write_through=True,\n             )\n             if targetfd in patchsysdict:\n"
    },
    "pytest-dev__pytest-7571": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-7571",
        "model_patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\nindex 11031f2f2..a3f0b1521 100644\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -432,7 +432,8 @@ class LogCaptureFixture:\n         \"\"\"\n         logger_obj = logging.getLogger(logger)\n         # save the original log-level to restore it during teardown\n-        self._initial_logger_levels.setdefault(logger, logger_obj.level)\n+        if logger not in self._initial_logger_levels:\n+            self._initial_logger_levels[logger] = logger_obj.level\n         logger_obj.setLevel(level)\n         self.handler.setLevel(level)\n \n"
    },
    "pytest-dev__pytest-7982": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-7982",
        "model_patch": "diff --git a/src/_pytest/pathlib.py b/src/_pytest/pathlib.py\nindex f0bdb1481..b96cba069 100644\n--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -558,7 +558,7 @@ def visit(\n     entries = sorted(os.scandir(path), key=lambda entry: entry.name)\n     yield from entries\n     for entry in entries:\n-        if entry.is_dir(follow_symlinks=False) and recurse(entry):\n+        if entry.is_dir() and recurse(entry):\n             yield from visit(entry.path, recurse)\n \n \n"
    },
    "pytest-dev__pytest-8399": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "pytest-dev__pytest-8399",
        "model_patch": "diff --git a/src/_pytest/unittest.py b/src/_pytest/unittest.py\nindex 719eb4e88..3f88d7a9e 100644\n--- a/src/_pytest/unittest.py\n+++ b/src/_pytest/unittest.py\n@@ -144,7 +144,7 @@ def _make_xunit_fixture(\n         scope=scope,\n         autouse=True,\n         # Use a unique name to speed up lookup.\n-        name=f\"unittest_{setup_name}_fixture_{obj.__qualname__}\",\n+        name=f\"_unittest_{setup_name}_fixture_{obj.__qualname__}\",\n     )\n     def fixture(self, request: FixtureRequest) -> Generator[None, None, None]:\n         if _is_skipped(self):\n"
    },
    "scikit-learn__scikit-learn-10297": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "scikit-learn__scikit-learn-10297",
        "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex 911c74ae3..6469cdbcf 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -1301,6 +1301,12 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n         weights inversely proportional to class frequencies in the input data\n         as ``n_samples / (n_classes * np.bincount(y))``\n \n+    store_cv_values : boolean, default=False\n+        Flag indicating if the cross-validation values corresponding to\n+        each alpha should be stored in the `cv_values_` attribute (see\n+        below). This flag is only compatible with `cv=None` (i.e. using\n+        Generalized Cross-Validation).\n+\n     Attributes\n     ----------\n     cv_values_ : array, shape = [n_samples, n_alphas] or \\\n@@ -1333,10 +1339,11 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n+                 normalize=False, scoring=None, cv=None, class_weight=None,\n+                 store_cv_values=False):\n         super(RidgeClassifierCV, self).__init__(\n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n-            scoring=scoring, cv=cv)\n+            scoring=scoring, cv=cv, store_cv_values=store_cv_values)\n         self.class_weight = class_weight\n \n     def fit(self, X, y, sample_weight=None):\n"
    },
    "scikit-learn__scikit-learn-10844": {
        "model_name_or_path": "openrouter_qwen_qwen3-coder",
        "instance_id": "scikit-learn__scikit-learn-10844",
        "model_patch": "diff --git a/sklearn/metrics/cluster/supervised.py b/sklearn/metrics/cluster/supervised.py\nindex a987778ae..9bcca75a2 100644\n--- a/sklearn/metrics/cluster/supervised.py\n+++ b/sklearn/metrics/cluster/supervised.py\n@@ -856,7 +856,7 @@ def fowlkes_mallows_score(labels_true, labels_pred, sparse=False):\n     tk = np.dot(c.data, c.data) - n_samples\n     pk = np.sum(np.asarray(c.sum(axis=0)).ravel() ** 2) - n_samples\n     qk = np.sum(np.asarray(c.sum(axis=1)).ravel() ** 2) - n_samples\n-    return tk / np.sqrt(pk * qk) if tk != 0. else 0.\n+    return np.sqrt(tk / pk) * np.sqrt(tk / qk) if tk != 0. else 0.\n \n \n def entropy(labels):\n"
    }
}